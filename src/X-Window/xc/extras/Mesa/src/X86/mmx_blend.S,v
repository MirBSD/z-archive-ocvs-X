head	1.2;
branch	1.1.1;
access;
symbols
	tg-mergetmp-2:1.1.1.3
	cvs-200410241530:1.1.1.3
	cvs-200410012000:1.1.1.3
	cvs-200407141120:1.1.1.3
	cvs-200406231010:1.1.1.3
	MIRBSD_7quater:1.1.1.2
	cvs-200405271510:1.1.1.3
	XFree86_4_4_0:1.1.9.1
	cvs-200403021700:1.1.1.3
	XFREE86_20040213:1.1.9.1
	xc:1.1.9
	cvs-200401291925:1.1.1.2
	MIRBSD_7_ALPHA:1.1.1.2.0.4
	MIRBSD_7:1.1.1.2.0.2
	MIRBSD_7ter:1.1.1.2
	cvs-20011091815:1.1.1.2
	cvs-200309162130:1.1.1.2
	cvs-200308302005:1.1.1.2
	ctmx-0387:1.1.1.2
	ctmx-0384:1.1.1.2
	MIRBSD_5:1.1.1.2
	ctmx-0375:1.1.1.2
	ctmx-0373:1.1.1.2
	ctm-0371:1.1.1.2
	ctm-0370:1.1.1.2
	MIRBSD_4:1.1.1.2
	ctm-0363:1.1.1.2
	ctm-0359:1.1.1.2
	ctm-0349:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@# @;


1.2
date	2003.05.16.16.28.32;	author tg;	state dead;
branches;
next	1.1;

1.1
date	2003.03.22.20.01.06;	author tg;	state Exp;
branches
	1.1.1.1
	1.1.9.1;
next	;

1.1.1.1
date	2003.03.22.20.01.06;	author tg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2003.04.08.18.20.11;	author tg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2004.03.02.17.29.39;	author tg;	state Stab;
branches;
next	;

1.1.9.1
date	2004.02.14.19.04.58;	author tg;	state Exp;
branches;
next	;


desc
@@


1.2
log
@remove a bunch of files not used in MirBSD - clean tree. People who want them got cvs.
@
text
@#include "assyntax.h"


SEG_TEXT


ALIGNTEXT16
GLOBL GLNAME(gl_mmx_blend_transparency)

GLNAME( gl_mmx_blend_transparency ):
    PUSH_L    ( EBP )
    MOV_L     ( ESP, EBP )
    SUB_L     ( CONST(52), ESP )
    PUSH_L    ( EBX )
    MOV_L     ( CONST(16711680), REGOFF(-8, EBP) )
    MOV_L     ( CONST(16711680), REGOFF(-4, EBP) )
    MOV_L     ( CONST(0), REGOFF(-16, EBP) )
    MOV_L     ( CONST(-1), REGOFF(-12, EBP) )
    MOV_L     ( CONST(-1), REGOFF(-24, EBP) )
    MOV_L     ( CONST(0), REGOFF(-20, EBP) )
    MOV_L     ( REGOFF(24, EBP), EAX )
    ADD_L     ( CONST(4), EAX )
    MOV_L     ( EAX, EDX )
    AND_L     ( REGOFF(20, EBP), EDX )
    MOV_L     ( EDX, EAX )
    AND_L     ( CONST(4), EAX )
    CMP_L     ( CONST(8), EAX )
    JNE       ( LLBL(GMBT_2) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    ADD_L     ( CONST(3), EAX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(EAX), DL )
    MOV_L     ( EDX, REGOFF(-32, EBP) )
    MOV_L     ( CONST(255), EAX )
    MOV_L     ( EAX, EBX )
    SUB_L     ( REGOFF(-32, EBP), EBX )
    MOV_L     ( EBX, REGOFF(-36, EBP) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(EAX), DL )
    MOV_L     ( EDX, EAX )
    IMUL_L    ( REGOFF(-32, EBP), EAX )
    MOV_L     ( REGOFF(24, EBP), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EDX )
    IMUL_L    ( REGOFF(-36, EBP), EDX )
    ADD_L     ( EDX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-40, EBP) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    INC_L     ( EAX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(EAX), DL )
    MOV_L     ( EDX, EAX )
    IMUL_L    ( REGOFF(-32, EBP), EAX )
    MOV_L     ( REGOFF(24, EBP), EDX )
    INC_L     ( EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EDX )
    IMUL_L    ( REGOFF(-36, EBP), EDX )
    ADD_L     ( EDX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-44, EBP) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    ADD_L     ( CONST(2), EAX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(EAX), DL )
    MOV_L     ( EDX, EAX )
    IMUL_L    ( REGOFF(-32, EBP), EAX )
    MOV_L     ( REGOFF(24, EBP), EDX )
    ADD_L     ( CONST(2), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EDX )
    IMUL_L    ( REGOFF(-36, EBP), EDX )
    ADD_L     ( EDX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-48, EBP) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    ADD_L     ( CONST(3), EAX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(EAX), DL )
    MOV_L     ( EDX, EAX )
    IMUL_L    ( REGOFF(-32, EBP), EAX )
    MOV_L     ( REGOFF(24, EBP), EDX )
    ADD_L     ( CONST(3), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EDX )
    IMUL_L    ( REGOFF(-36, EBP), EDX )
    ADD_L     ( EDX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-52, EBP) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    MOV_B     ( REGOFF(-40, EBP), DL )
    MOV_B     ( DL, REGIND(EAX) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    INC_L     ( EAX )
    MOV_B     ( REGOFF(-44, EBP), DL )
    MOV_B     ( DL, REGIND(EAX) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    ADD_L     ( CONST(2), EAX )
    MOV_B     ( REGOFF(-48, EBP), DL )
    MOV_B     ( DL, REGIND(EAX) )
    MOV_L     ( REGOFF(20, EBP), EAX )
    ADD_L     ( CONST(3), EAX )
    MOV_B     ( REGOFF(-52, EBP), DL )
    MOV_B     ( DL, REGIND(EAX) )
    INC_L     ( REGOFF(16, EBP) )
    ADD_L     ( CONST(4), REGOFF(20, EBP) )
    ADD_L     ( CONST(4), REGOFF(24, EBP) )
    DEC_L     ( REGOFF(12, EBP) )
LLBL(GMBT_2):

    CMP_L     ( CONST(0), REGOFF(12, EBP) )
    JE        ( LLBL(GMBT_3) )
    MOV_L     ( CONST(0), REGOFF(-28, EBP) )
ALIGNTEXT4
LLBL(GMBT_4):

    MOV_L     ( REGOFF(12, EBP), EDX )
    MOV_L     ( EDX, EAX )
    SHR_L     ( CONST(1), EAX )
    CMP_L     ( EAX, REGOFF(-28, EBP) )
    JB        ( LLBL(GMBT_7) )
    JMP       ( LLBL(GMBT_5) )
ALIGNTEXT16
LLBL(GMBT_7):

    MOV_L     ( REGOFF(-28, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,2), EDX )
    MOV_L     ( REGOFF(16, EBP), EAX )
    CMP_B     ( CONST(0), REGBI(EAX,EDX) )
    JE        ( LLBL(GMBT_6) )
    MOV_L     ( REGOFF(-28, EBP), EAX )
    MOV_L     ( EAX, EDX )
    LEA_L     ( REGDIS(0,EDX,8), ECX )
    MOV_L     ( ECX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    MOV_L     ( REGOFF(-28, EBP), EDX )
    MOV_L     ( EDX, ECX )
    LEA_L     ( REGDIS(0,ECX,8), EDX )
    MOV_L     ( EDX, ECX )
    ADD_L     ( REGOFF(24, EBP), ECX )

    MOVQ      ( REGIND(EAX), MM4 )
    PXOR      ( MM5, MM5 )
    MOVQ      ( MM4, MM1 )
    MOVQ      ( REGIND(ECX), MM7 )
    PUNPCKLBW ( MM5, MM1 )
    MOVQ      ( MM7, MM6 )
    MOVQ      ( MM1, MM0 )
    PUNPCKLBW ( MM5, MM6 )
    MOVQ      ( MM1, MM2 )
    PSRLQ     ( CONST(48), MM0 )
    PUNPCKHBW ( MM5, MM4 )
    PACKSSDW  ( MM0, MM0 )
    MOVQ      ( MM0, MM3 )
    PUNPCKHBW ( MM5, MM7 )
    PSLLQ     ( CONST(16), MM3 )
    POR       ( REGOFF(-8, EBP), MM0 )
    PUNPCKLWD ( MM6, MM1 )
    PSUBW     ( MM3, MM0 )
    PUNPCKHWD ( MM6, MM2 )
    MOVQ      ( MM4, MM3 )
    PSRLQ     ( CONST(48), MM3 )
    PACKSSDW  ( MM3, MM3 )
    MOVQ      ( MM3, MM6 )
    POR       ( REGOFF(-8, EBP), MM3 )
    PSLLQ     ( CONST(16), MM6 )
    PSUBW     ( MM6, MM3 )
    MOVQ      ( MM4, MM5 )
    PUNPCKLWD ( MM7, MM4 )
    PUNPCKHWD ( MM7, MM5 )
    PMADDWD   ( MM0, MM1 )
    PMADDWD   ( MM3, MM4 )
    PMADDWD   ( MM0, MM2 )
    PMADDWD   ( MM3, MM5 )
    PSRLD     ( CONST(8), MM1 )
    PSRLD     ( CONST(8), MM2 )
    PSRLD     ( CONST(8), MM4 )
    PACKSSDW  ( MM2, MM1 )
    PSRLD     ( CONST(8), MM5 )
    PACKUSWB  ( MM1, MM1 )
    PACKSSDW  ( MM5, MM4 )
    PAND      ( REGOFF(-24, EBP), MM1 )
    PACKUSWB  ( MM4, MM4 )
    PAND      ( REGOFF(-16, EBP), MM4 )
    POR       ( MM1, MM4 )
    MOVQ      ( MM4, REGIND(EAX) )


LLBL(GMBT_8):

LLBL(GMBT_6):

    INC_L     ( REGOFF(-28, EBP) )
    JMP       ( LLBL(GMBT_4) )
ALIGNTEXT16
LLBL(GMBT_5):


    EMMS

LLBL(GMBT_3):

    MOV_L     ( REGOFF(12, EBP), EAX )
    AND_L     ( CONST(1), EAX )
    TEST_L    ( EAX, EAX )
    JE        ( LLBL(GMBT_9) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-1, EAX), EDX )
    XOR_L     ( EAX, EAX )
    MOV_B     ( REGIND(EDX), AL )
    MOV_L     ( EAX, REGOFF(-52, EBP) )
    MOV_L     ( CONST(255), EAX )
    MOV_L     ( EAX, EBX )
    SUB_L     ( REGOFF(-52, EBP), EBX )
    MOV_L     ( EBX, REGOFF(-48, EBP) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-4, EAX), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EAX )
    IMUL_L    ( REGOFF(-52, EBP), EAX )
    MOV_L     ( REGOFF(12, EBP), EDX )
    LEA_L     ( REGDIS(0,EDX,4), ECX )
    MOV_L     ( ECX, EDX )
    ADD_L     ( REGOFF(24, EBP), EDX )
    LEA_L     ( REGOFF(-4, EDX), ECX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(ECX), DL )
    MOV_L     ( EDX, ECX )
    IMUL_L    ( REGOFF(-48, EBP), ECX )
    ADD_L     ( ECX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-44, EBP) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-3, EAX), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EAX )
    IMUL_L    ( REGOFF(-52, EBP), EAX )
    MOV_L     ( REGOFF(12, EBP), EDX )
    LEA_L     ( REGDIS(0,EDX,4), ECX )
    MOV_L     ( ECX, EDX )
    ADD_L     ( REGOFF(24, EBP), EDX )
    LEA_L     ( REGOFF(-3, EDX), ECX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(ECX), DL )
    MOV_L     ( EDX, ECX )
    IMUL_L    ( REGOFF(-48, EBP), ECX )
    ADD_L     ( ECX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-40, EBP) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-2, EAX), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EAX )
    IMUL_L    ( REGOFF(-52, EBP), EAX )
    MOV_L     ( REGOFF(12, EBP), EDX )
    LEA_L     ( REGDIS(0,EDX,4), ECX )
    MOV_L     ( ECX, EDX )
    ADD_L     ( REGOFF(24, EBP), EDX )
    LEA_L     ( REGOFF(-2, EDX), ECX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(ECX), DL )
    MOV_L     ( EDX, ECX )
    IMUL_L    ( REGOFF(-48, EBP), ECX )
    ADD_L     ( ECX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-36, EBP) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-1, EAX), EDX )
    XOR_L     ( ECX, ECX )
    MOV_B     ( REGIND(EDX), CL )
    MOV_L     ( ECX, EAX )
    IMUL_L    ( REGOFF(-52, EBP), EAX )
    MOV_L     ( REGOFF(12, EBP), EDX )
    LEA_L     ( REGDIS(0,EDX,4), ECX )
    MOV_L     ( ECX, EDX )
    ADD_L     ( REGOFF(24, EBP), EDX )
    LEA_L     ( REGOFF(-1, EDX), ECX )
    XOR_L     ( EDX, EDX )
    MOV_B     ( REGIND(ECX), DL )
    MOV_L     ( EDX, ECX )
    IMUL_L    ( REGOFF(-48, EBP), ECX )
    ADD_L     ( ECX, EAX )
    MOV_L     ( EAX, EBX )
    SAR_L     ( CONST(8), EBX )
    MOV_L     ( EBX, REGOFF(-32, EBP) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-4, EAX), EDX )
    MOV_B     ( REGOFF(-44, EBP), AL )
    MOV_B     ( AL, REGIND(EDX) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-3, EAX), EDX )
    MOV_B     ( REGOFF(-40, EBP), AL )
    MOV_B     ( AL, REGIND(EDX) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-2, EAX), EDX )
    MOV_B     ( REGOFF(-36, EBP), AL )
    MOV_B     ( AL, REGIND(EDX) )
    MOV_L     ( REGOFF(12, EBP), EAX )
    LEA_L     ( REGDIS(0,EAX,4), EDX )
    MOV_L     ( EDX, EAX )
    ADD_L     ( REGOFF(20, EBP), EAX )
    LEA_L     ( REGOFF(-1, EAX), EDX )
    MOV_B     ( REGOFF(-32, EBP), AL )
    MOV_B     ( AL, REGIND(EDX) )
LLBL(GMBT_9):

LLBL(GMBT_1):

    MOV_L     ( REGOFF(-56, EBP), EBX )
    MOV_L     ( EBP, ESP )
    POP_L     ( EBP )
    RET
@


1.1
log
@Initial revision
@
text
@@


1.1.9.1
log
@OpenBSD just has imported exactly this tree into their vendor branch,
called the same tag, in XF4/xc
This is, apparently, the last XFree86 snapshot before the licence change
(ie, addition of the advertising clause)

Since the developers don't see any problems with that, and we would like
to integrate improvements done by the remaining one or two (or so) XFree86
developers (j/k), this prepares enabling us to update X-Window in the future.
@
text
@d1 1
a1 1
/* $XFree86: xc/extras/Mesa/src/X86/mmx_blend.S,v 1.7 2003/11/04 01:03:35 dawes Exp $ */
a2 360
/*
 * Written by José Fonseca <j_r_fonseca@@yahoo.co.uk>
 */

#include "matypes.h"


/* integer multiplication - alpha plus one
 *
 * makes the following approximation to the division (Sree)
 *
 *   rgb*a/255 ~= (rgb*(a+1)) >> 256
 *
 * which is the fastest method that satisfies the following OpenGL criteria
 *
 *   0*0 = 0 and 255*255 = 255
 *
 * note that MX1 is a register with 0xffffffffffffffff constant which can be easily obtained making
 *
 *   PCMPEQW    ( MX1, MX1 )
 */
#define GMB_MULT_AP1( MP1, MA1, MP2, MA2, MX1 ) \
    PSUBW      ( MX1, MA1 )			/*   a1 + 1  |   a1 + 1  |   a1 + 1  |   a1 + 1  */	;\
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
													;\
TWO(PSUBW      ( MX1, MA2 ))			/*   a2 + 1  |   a2 + 1  |   a2 + 1  |   a2 + 1  */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*               t1 >> 8 ~= t1/255               */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*               t2 >> 8 ~= t2/255               */	


/* integer multiplication - geometric series
 *
 * takes the geometric series approximation to the division
 *
 *   t/255 = (t >> 8) + (t >> 16) + (t >> 24) ..
 *
 * in this case just the first two terms to fit in 16bit arithmetic
 *
 *   t/255 ~= (t + (t >> 8)) >> 8
 *
 * note that just by itself it doesn't satisfies the OpenGL criteria, as 255*255 = 254, 
 * so the special case a = 255 must be accounted or roundoff must be used
 */
#define GMB_MULT_GS( MP1, MA1, MP2, MA2 ) \
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
													;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* integer multiplication - geometric series plus rounding
 *
 * when using a geometric series division instead of truncating the result 
 * use roundoff in the approximation (Jim Blinn)
 *
 *   t = rgb*a + 0x80
 *
 * achieving the exact results
 *
 * note that M80 is register with the 0x0080008000800080 constant
 */
#define GMB_MULT_GSR( MP1, MA1, MP2, MA2, M80 ) \
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
    PADDW      ( M80, MA1 )			/*                 t1 += 0x80                    */	;\
													;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
TWO(PADDW      ( M80, MA2 ))			/*                 t2 += 0x80                    */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
													;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* linear interpolation - geometric series 
 */
#define GMB_LERP_GS( MP1, MQ1, MA1, MP2, MQ2, MA2) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* linear interpolation - geometric series with roundoff
 *
 * this is a generalization of Blinn's formula to signed arithmetic
 *
 * note that M80 is a register with the 0x0080008000800080 constant
 */
#define GMB_LERP_GSR( MP1, MQ1, MA1, MP2, MQ2, MA2, M80) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    PSRLW      ( CONST(15), MP1 )		/*                 q1 > p1 ? 1 : 0               */	;\
TWO(PSRLW      ( CONST(15), MP2 ))		/*                 q2 > q2 ? 1 : 0               */	;\
													;\
    PSLLW      ( CONST(8), MP1 )		/*             q1 > p1 ? 0x100 : 0               */	;\
TWO(PSLLW      ( CONST(8), MP2 ))		/*             q2 > q2 ? 0x100 : 0               */	;\
													;\
    PSUBW      ( MP1, MA1 )			/*                  t1 -=? 0x100                 */	;\
TWO(PSUBW      ( MP2, MA2 ))			/*                  t2 -=? 0x100                 */	;\
 													;\
    PADDW      ( M80, MA1 )			/*                 t1 += 0x80                    */	;\
TWO(PADDW      ( M80, MA2 ))			/*                 t2 += 0x80                    */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* linear interpolation - geometric series with correction
 *
 * instead of the roundoff this adds a small correction to satisfy the OpenGL criteria
 *
 *   t/255 ~= (t + (t >> 8) + (t >> 15)) >> 8
 *
 * note that although is faster than rounding off it doesn't give always the exact results
 */
#define GMB_LERP_GSC( MP1, MQ1, MA1, MP2, MQ2, MA2) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MA1, MP1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(7), MA1 )		/*                    t1 >> 15                   */	;\
													;\
TWO(PADDW      ( MA2, MP2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(7), MA2 ))		/*                    t2 >> 15                   */	;\
													;\
    PADDW      ( MP1, MA1 )			/*  t1 + (t1 >> 8) + (t1 >>15) ~= (t1/255) << 8  */	;\
TWO(PADDW      ( MP2, MA2 ))			/*  t2 + (t2 >> 8) + (t2 >>15) ~= (t2/255) << 8  */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* common blending setup code
 *
 * note that M00 is a register with 0x0000000000000000 constant which can be easily obtained making
 *
 *   PXOR      ( M00, M00 )
 */
#define GMB_LOAD(rgba, dest, MPP, MQQ) \
ONE(MOVD       ( REGIND(rgba), MPP ))		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */	;\
ONE(MOVD       ( REGIND(dest), MQQ ))		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */	;\
													;\
TWO(MOVQ       ( REGIND(rgba), MPP ))		/* qa2 | qb2 | qg2 | qr2 | qa1 | qb1 | qg1 | qr1 */	;\
TWO(MOVQ       ( REGIND(dest), MQQ ))		/* pa2 | pb2 | pg2 | pr2 | pa1 | pb1 | pg1 | pr1 */

#define GMB_UNPACK(MP1, MQ1, MP2, MQ2, M00) \
TWO(MOVQ       ( MP1, MP2 ))										;\
TWO(MOVQ       ( MQ1, MQ2 ))										;\
													;\
    PUNPCKLBW  ( M00, MQ1 )			/*    qa1    |    qb1    |    qg1    |    qr1    */	;\
TWO(PUNPCKHBW  ( M00, MQ2 ))                    /*    qa2    |    qb2    |    qg2    |    qr2    */	;\
    PUNPCKLBW  ( M00, MP1 )			/*    pa1    |    pb1    |    pg1    |    pr1    */	;\
TWO(PUNPCKHBW  ( M00, MP2 ))                    /*    pa2    |    pb2    |    pg2    |    pr2    */

#define GMB_ALPHA(MP1, MA1, MP2, MA2) \
    MOVQ       ( MP1, MA1 )										;\
TWO(MOVQ       ( MP2, MA2 ))										;\
													;\
    PUNPCKHWD  ( MA1, MA1 )			/*    pa1    |    pa1    |           |           */	;\
TWO(PUNPCKHWD  ( MA2, MA2 ))			/*    pa2    |    pa2    |           |           */	;\
    PUNPCKHDQ  ( MA1, MA1 )                     /*    pa1    |    pa1    |    pa1    |    pa1    */	;\
TWO(PUNPCKHDQ  ( MA2, MA2 ))                    /*    pa2    |    pa2    |    pa2    |    pa2    */

#define GMB_PACK( MS1, MS2 ) \
    PACKUSWB   ( MS2, MS1 )			/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */	;\

#define GMB_STORE(rgba, MSS ) \
ONE(MOVD       ( MSS, REGIND(rgba) ))		/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */	;\
TWO(MOVQ       ( MSS, REGIND(rgba) ))		/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */


    SEG_DATA

ALIGNDATA8
const_0080:
    D_LONG 0x00800080, 0x00800080

const_80:
    D_LONG 0x80808080, 0x80808080

    SEG_TEXT


/* Blend transparency function
 */

#define TAG(x) CONCAT(x,_transparency)
#define LLTAG(x) LLBL2(x,_transparency)

#define INIT \
    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */

#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    GMB_UNPACK( MM1, MM2, MM4, MM5, MM0 )								;\
    GMB_ALPHA( MM1, MM3, MM4, MM6 )									;\
    GMB_LERP_GSC( MM1, MM2, MM3, MM4, MM5, MM6 )							;\
    GMB_PACK( MM3, MM6 )										;\
    GMB_STORE( rgba, MM3 )

#include "mmx_blendtmp.h"


/* Blend add function
 *
 * FIXME: Add some loop unrolling here...
 */

#define TAG(x) CONCAT(x,_add)
#define LLTAG(x) LLBL2(x,_add)

#define INIT

#define MAIN( rgba, dest ) \
ONE(MOVD       ( REGIND(rgba), MM1 ))		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */	;\
ONE(MOVD       ( REGIND(dest), MM2 ))		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */	;\
ONE(PADDUSB    ( MM2, MM1 ))										;\
ONE(MOVD       ( MM1, REGIND(rgba) ))		/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */	;\
													;\
TWO(MOVQ       ( REGIND(rgba), MM1 ))		/* qa2 | qb2 | qg2 | qr2 | qa1 | qb1 | qg1 | qr1 */	;\
TWO(PADDUSB    ( REGIND(dest), MM1 ))		/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */	;\
TWO(MOVQ       ( MM1, REGIND(rgba) ))

#include "mmx_blendtmp.h"


/* Blend min function
 */

#define TAG(x) CONCAT(x,_min)
#define LLTAG(x) LLBL2(x,_min)

#define INIT \
    MOVQ       ( CONTENT(const_80), MM7 )	/* 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80*/

#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    MOVQ       ( MM1, MM3 )										;\
    MOVQ       ( MM2, MM4 )										;\
    PXOR       ( MM7, MM3 )			/*              unsigned -> signed               */	;\
    PXOR       ( MM7, MM4 )			/*              unsigned -> signed               */	;\
    PCMPGTB    ( MM3, MM4 )			/*                 q > p ? 0xff : 0x00           */	;\
    PAND       ( MM4, MM1 )			/*                 q > p ? p : 0                 */	;\
    PANDN      ( MM2, MM4 )			/*                 q > p ? 0 : q                 */	;\
    POR        ( MM1, MM4 )			/*                 q > p ? p : q                 */	;\
    GMB_STORE( rgba, MM4 )

#include "mmx_blendtmp.h"


/* Blend max function
 */

#define TAG(x) CONCAT(x,_max)
#define LLTAG(x) LLBL2(x,_max)

#define INIT \
    MOVQ       ( CONTENT(const_80), MM7 )	/* 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80*/

#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    MOVQ       ( MM1, MM3 )										;\
    MOVQ       ( MM2, MM4 )										;\
    PXOR       ( MM7, MM3 )			/*              unsigned -> signed               */	;\
    PXOR       ( MM7, MM4 )			/*              unsigned -> signed               */	;\
    PCMPGTB    ( MM3, MM4 )			/*                 q > p ? 0xff : 0x00           */	;\
    PAND       ( MM4, MM2 )			/*                 q > p ? q : 0                 */	;\
    PANDN      ( MM1, MM4 )			/*                 q > p ? 0 : p                 */	;\
    POR        ( MM2, MM4 )			/*                 q > p ? p : q                 */	;\
    GMB_STORE( rgba, MM4 )

#include "mmx_blendtmp.h"


/* Blend modulate function
 */

#define TAG(x) CONCAT(x,_modulate)
#define LLTAG(x) LLBL2(x,_modulate)

#define INIT \
    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */	;\
    MOVQ       ( CONTENT(const_0080), MM7 )	/*   0x0080  |   0x0080  |   0x0080  |   0x0080  */

#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    GMB_UNPACK( MM1, MM2, MM4, MM5, MM0 )								;\
    GMB_MULT_GSR( MM1, MM2, MM4, MM5, MM7 )								;\
    GMB_PACK( MM2, MM5 )										;\
    GMB_STORE( rgba, MM2 )
d4 1
a4 1
#include "mmx_blendtmp.h"
d6 347
@


1.1.1.1
log
@Import OpenBSD 3.3 XF4 repository from CTM 3132 the first time
This finalizes starting an OpenBSD-mirabile (aka MirBSD) repository.

### MirBSD is:
# Copyright (c) 1982-2003 by Thorsten "mirabile" Glaser <x86@@ePost.de>
# Copyright © 1968-2003  The authors of And contributors to UNIX®, the
#       C Language, BSD/Berkeley Unix; 386BSD, NetBSD 1.1 and OpenBSD.
#
# Anyone who obtained a copy of this work is hereby permitted to freely use,
# distribute, modify, merge, sublicence, give away or sell it as long as the
# authors are given due credit and the following notice is retained:
#
# This work is provided "as is", with no explicit or implicit warranty what-
# soever. Use it only at your own risk. In no event may an author or contri-
# butor be held liable for any damage, directly or indirectly, that origina-
# ted through or is caused by creation or modification of this work.

MirBSD is my private tree. MirBSD does not differ very much from OpenBSD
and intentionally tracks OpenBSD. That's why it _is_ OpenBSD, just not the
official one. It's like with DarrenBSD.

At time of this writing, no advertising for MirBSD must be done,
because the advertising clause has not yet been sorted out.

http://templeofhate.com/tglaser/MirBSD/index.php
@
text
@@


1.1.1.2
log
@The X-Windowing System

Import XFree86 4.3 from OpenBSD by CTM, in the hope it's stable
@
text
@d1 1
a1 72
/*
 * Written by José Fonseca <j_r_fonseca@@yahoo.co.uk>
 */

#include "matypes.h"

/*
 * make the following approximation to the division (Sree)
 *
 *   rgb*a/255 ~= (rgb*(a+1)) >> 256
 *
 * which is the fastest method that satisfies the following OpenGL criteria
 *
 *   0*0 = 0 and 255*255 = 255
 *
 * note this one should be used alone
 */
#define GMBT_ALPHA_PLUS_ONE	0

/*
 * take the geometric series approximation to the division
 *
 *   t/255 = (t >> 8) + (t >> 16) + (t >> 24) ..
 *
 * in this case just the first two terms to fit in 16bit arithmetic
 *
 *   t/255 ~= (t + (t >> 8)) >> 8
 *
 * note that just by itself it doesn't satisfies the OpenGL criteria, as 255*255 = 254, 
 * so the special case a = 255 must be accounted or roundoff must be used
 */
#define GMBT_GEOMETRIC_SERIES	1

/*
 * when using a geometric series division instead of truncating the result 
 * use roundoff in the approximation (Jim Blinn)
 *
 *   t = rgb*a + 0x80
 *
 * achieving the exact results
 */
#define GMBT_ROUNDOFF		0

/* instead of the roundoff this adds a small correction to satisfy the OpenGL criteria
 *
 *   t/255 ~= (t + (t >> 8) + (t >> 15)) >> 8
 *
 * note that although is faster than rounding off it doesn't give always the exact results
 */
#define GMBT_GEOMETRIC_CORRECTION	1

/*
 * do
 *
 *   s = (q - p)*a + q
 *
 * instead of
 *
 *   s = p*a + q*(1-a)
 *
 * this eliminates a multiply at the expense of
 * complicating the roundoff but is generally worth it
 */
#define GMBT_SIGNED_ARITHMETIC	1

#if GMBT_ROUNDOFF
    SEG_DATA

ALIGNDATA8
const_80:
	D_LONG 0x00800080, 0x00800080
#endif 
a2 1
   SEG_TEXT
d4 1
a4 2
ALIGNTEXT16
GLOBL GLNAME(_mesa_mmx_blend_transparency)
a5 10
/*
 * void blend_transparency( GLcontext *ctx,
 *                          GLuint n, 
 *                          const GLubyte mask[],
 *                          GLchan rgba[][4], 
 *                          CONST GLchan dest[][4] )
 * 
 * Common transparency blending mode.
 */
GLNAME( _mesa_mmx_blend_transparency ):
d7 2
a8 5
    PUSH_L     ( EBP )
    MOV_L      ( ESP, EBP )
    PUSH_L     ( ESI )
    PUSH_L     ( EDI )
    PUSH_L     ( EBX )
d10 125
a134 65
    MOV_L      ( REGOFF(12, EBP), ECX )		/* n */
    CMP_L      ( CONST(0), ECX)
    JE         ( LLBL (GMBT_return) )

    MOV_L      ( REGOFF(16, EBP), EBX )		/* mask */
    MOV_L      ( REGOFF(20, EBP), EDI )         /* rgba */
    MOV_L      ( REGOFF(24, EBP), ESI )         /* dest */
    
    TEST_L     ( CONST(4), EDI )		/* align rgba on an 8-byte boundary */
    JZ         ( LLBL (GMBT_align_end) )

    CMP_B      ( CONST(0), REGIND(EBX) )	/* *mask == 0 */
    JE         ( LLBL (GMBT_align_continue) )

    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */

    MOVD       ( REGIND(ESI), MM1 )		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */
    MOVD       ( REGIND(EDI), MM2 )		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */

    PUNPCKLBW  ( MM0, MM1 )			/*    qa1    |    qb1    |    qg1    |    qr1    */
    PUNPCKLBW  ( MM0, MM2 )			/*    pa1    |    pb1    |    pg1    |    pr1    */

    MOVQ       ( MM2, MM3 )

    PUNPCKHWD  ( MM3, MM3 )			/*    pa1    |    pa1    |           |           */
    PUNPCKHDQ  ( MM3, MM3 )                     /*    pa1    |    pa1    |    pa1    |    pa1    */

#if GMBT_ALPHA_PLUS_ONE
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */

    PSUBW      ( MM4, MM3 )                     /*   pa1 + 1 |   pa1 + 1 |   pa1 + 1 |   pa1 + 1 */
#endif

#if GMBT_SIGNED_ARITHMETIC
    PSUBW      ( MM1, MM2 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */

    PSLLW      ( CONST(8), MM1 )		/*                    q1 << 8                    */

#if GMBT_ROUNDOFF
    MOVQ       ( MM2, MM4 )
#endif

    PMULLW     ( MM3, MM2 )			/*              t1 = (q1 - p1)*pa1               */

#if GMBT_ROUNDOFF
    PSRLW      ( CONST(15), MM4 )		/*                 q1 > p1 ? 1 : 0               */

    PSLLW      ( CONST(8), MM4 )		/*             q1 > p1 ? 0x100 : 0               */

    PSUBW      ( MM4, MM2 )                     /*                  t1 -=? 0x100                 */
#endif

#else
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */
    PUNPCKLBW  ( MM0, MM4 )			/*   0x00ff  |   0x00ff  |   0x00ff  |   0x00ff  */
    MOVQ       ( MM4, MM0 )
    
    PMULLW     ( MM3, MM2 )			/*                     p1*pa1                    */

    PSUBW      ( MM3, MM0 )			/* 255 - pa1 | 255 - pa1 | 255 - pa1 | 255 - pa1 */

    PMULLW     ( MM0, MM1 )			/*                  q1*(255 - pa1)               */

    PADDW      ( MM1, MM2 )			/*           t1 = p1*pa1 + q1*(255 - pa1)        */
#endif
d136 61
a196 2
#if GMBT_ROUNDOFF
    MOVQ       ( CONTENT(const_80), MM4 )
a197 2
    PADDW      ( MM4, MM2 )                     /*                 t1 += 0x80                    */
#endif
d199 1
a199 2
#if GMBT_GEOMETRIC_SERIES
    MOVQ       ( MM2, MM3 )
d201 1
a201 25
    PSRLW      ( CONST(8), MM3 )		/*                    t1 >> 8                    */

    PADDW      ( MM3, MM2 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */
#endif

#if GMBT_SIGNED_ARITHMETIC
    PADDW      ( MM1, MM2 )			/*              (t1/255 + q1) << 8               */
#endif

    PSRLW      ( CONST(8), MM2 )		/*    sa1    |    sb1    |    sg1    |    sr1    */
    
    PACKUSWB   ( MM0, MM2 )			/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */
    MOVD       ( MM2, REGIND(EDI) )

LLBL (GMBT_align_continue):

    DEC_L      ( ECX )				/* n -= 1 */
    INC_L      ( EBX )		                /* mask += 1 */
    ADD_L      ( CONST(4), EDI )		/* rgba += 1 */
    ADD_L      ( CONST(4), ESI )		/* dest += 1 */ 

LLBL (GMBT_align_end):

    CMP_L      ( CONST(2), ECX)
    JB         ( LLBL (GMBT_loop_end) )
d203 2
d206 1
a206 208
LLBL (GMBT_loop_begin):

    CMP_W      ( CONST(0), REGIND(EBX) )	/* *mask == 0 && *(mask + 1) == 0 */
    JE         ( LLBL (GMBT_loop_continue) )

    /* NOTE: the instruction pairing when multiple pipelines are available must be checked */

    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */

    MOVQ       ( REGIND(ESI), MM7 )		/* qa2 | qb2 | qg2 | qr2 | qa1 | qb1 | qg1 | qr1 */
    MOVQ       ( REGIND(EDI), MM6 )		/* pa2 | pb2 | pg2 | pr2 | pa1 | pb1 | pg1 | pr1 */

    MOVQ       ( MM7, MM1 )
    MOVQ       ( MM6, MM2 )

    PUNPCKLBW  ( MM0, MM1 )			/*    qa1    |    qb1    |    qg1    |    qr1    */
    PUNPCKHBW  ( MM0, MM7 )                     /*    qa2    |    qb2    |    qg2    |    qr2    */
    PUNPCKLBW  ( MM0, MM2 )			/*    pa1    |    pb1    |    pg1    |    pr1    */
    PUNPCKHBW  ( MM0, MM6 )                     /*    pa2    |    pb2    |    pg2    |    pr2    */

    MOVQ       ( MM2, MM3 )
    MOVQ       ( MM6, MM5 )

    PUNPCKHWD  ( MM3, MM3 )			/*    pa1    |    pa1    |           |           */
    PUNPCKHWD  ( MM5, MM5 )			/*    pa2    |    pa2    |           |           */
    PUNPCKHDQ  ( MM3, MM3 )                     /*    pa1    |    pa1    |    pa1    |    pa1    */
    PUNPCKHDQ  ( MM5, MM5 )                     /*    pa2    |    pa2    |    pa2    |    pa2    */

#if GMBT_ALPHA_PLUS_ONE
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */

    PSUBW      ( MM4, MM3 )                     /*   pa1 + 1 |   pa1 + 1 |   pa1 + 1 |   pa1 + 1 */
    PSUBW      ( MM4, MM5 )                     /*   pa2 + 1 |   pa2 + 1 |   pa2 + 1 |   pa2 + 1 */
#endif

#if GMBT_SIGNED_ARITHMETIC
    PSUBW      ( MM1, MM2 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */
    PSUBW      ( MM7, MM6 )                     /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */

    PSLLW      ( CONST(8), MM1 )		/*                    q1 << 8                    */
    PSLLW      ( CONST(8), MM7 )		/*                    q2 << 8                    */

#if GMBT_ROUNDOFF
    MOVQ       ( MM2, MM0 )
    MOVQ       ( MM6, MM4 )
#endif

    PMULLW     ( MM3, MM2 )			/*              t1 = (q1 - p1)*pa1               */
    PMULLW     ( MM5, MM6 )			/*              t2 = (q2 - p2)*pa2               */

#if GMBT_ROUNDOFF
    PSRLW      ( CONST(15), MM0 )		/*                 q1 > p1 ? 1 : 0               */
    PSRLW      ( CONST(15), MM4 )		/*                 q2 > q2 ? 1 : 0               */

    PSLLW      ( CONST(8), MM0 )		/*             q1 > p1 ? 0x100 : 0               */
    PSLLW      ( CONST(8), MM4 )		/*             q2 > q2 ? 0x100 : 0               */

    PSUBW      ( MM0, MM2 )                     /*                  t1 -=? 0x100                 */
    PSUBW      ( MM4, MM7 )                     /*                  t2 -=? 0x100                 */ 
#endif

#else
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */
    PUNPCKLBW  ( MM0, MM4 )			/*   0x00ff  |   0x00ff  |   0x00ff  |   0x00ff  */
    MOVQ       ( MM4, MM0 )
    
    PMULLW     ( MM3, MM2 )			/*                     p1*pa1                    */
    PMULLW     ( MM5, MM6 )			/*                     p2*pa2                    */

    PSUBW      ( MM3, MM0 )			/* 255 - pa1 | 255 - pa1 | 255 - pa1 | 255 - pa1 */
    PSUBW      ( MM5, MM4 )			/* 255 - pa2 | 255 - pa2 | 255 - pa2 | 255 - pa2 */

    PMULLW     ( MM0, MM1 )			/*                  q1*(255 - pa1)               */
    PMULLW     ( MM4, MM7 )			/*                  q2*(255 - pa2)               */

    PADDW      ( MM1, MM2 )			/*           t1 = p1*pa1 + q1*(255 - pa1)        */
    PADDW      ( MM7, MM6 )			/*           t2 = p2*pa2 + q2*(255 - pa2)        */
#endif

#if GMBT_ROUNDOFF
    MOVQ       ( CONTENT(const_80), MM4 )

    PADDW      ( MM4, MM2 )                     /*                 t1 += 0x80                    */
    PADDW      ( MM4, MM6 )                     /*                 t2 += 0x80                    */
#endif

#if GMBT_GEOMETRIC_SERIES
    MOVQ       ( MM2, MM3 )
    MOVQ       ( MM6, MM5 )

    PSRLW      ( CONST(8), MM3 )		/*                    t1 >> 8                    */
    PSRLW      ( CONST(8), MM5 )		/*                    t2 >> 8                    */

    PADDW      ( MM3, MM2 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */
    PADDW      ( MM5, MM6 )			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */

#if GMBT_GEOMETRIC_CORRECTION 
    PSRLW      ( CONST(7), MM3 )		/*                    t1 >> 15                   */
    PSRLW      ( CONST(7), MM5 )		/*                    t2 >> 15                   */

    PADDW      ( MM3, MM2 )			/*  t1 + (t1 >> 8) + (t1 >>15) ~= (t1/255) << 8  */
    PADDW      ( MM5, MM6 )			/*  t2 + (t2 >> 8) + (t2 >>15) ~= (t2/255) << 8  */
#endif
#endif

#if GMBT_SIGNED_ARITHMETIC
    PADDW      ( MM1, MM2 )			/*              (t1/255 + q1) << 8               */
    PADDW      ( MM7, MM6 )			/*              (t2/255 + q2) << 8               */
#endif

    PSRLW      ( CONST(8), MM2 )		/*    sa1    |    sb1    |    sg1    |    sr1    */
    PSRLW      ( CONST(8), MM6 )		/*    sa2    |    sb2    |    sg2    |    sr2    */
    
    PACKUSWB   ( MM6, MM2 )			/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */
    MOVQ       ( MM2, REGIND(EDI) )

LLBL (GMBT_loop_continue):

    DEC_L      ( ECX )
    DEC_L      ( ECX )				/* n -= 2 */
    ADD_L      ( CONST(2), EBX )		/* mask += 2 */
    ADD_L      ( CONST(8), EDI )		/* rgba += 2 */
    ADD_L      ( CONST(8), ESI )		/* dest += 2 */ 
    CMP_L      ( CONST(2), ECX )
    JAE        ( LLBL (GMBT_loop_begin) )

LLBL (GMBT_loop_end):

    CMP_L      ( CONST(1), ECX )
    JB         ( LLBL (GMBT_done) )

    CMP_B      ( CONST(0), REGIND(EBX) )	/* *mask == 0 */
    JE         ( LLBL (GMBT_done) )

    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */

    MOVD       ( REGIND(ESI), MM1 )		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */
    MOVD       ( REGIND(EDI), MM2 )		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */

    PUNPCKLBW  ( MM0, MM1 )			/*    qa1    |    qb1    |    qg1    |    qr1    */
    PUNPCKLBW  ( MM0, MM2 )			/*    pa1    |    pb1    |    pg1    |    pr1    */

    MOVQ       ( MM2, MM3 )

    PUNPCKHWD  ( MM3, MM3 )			/*    pa1    |    pa1    |           |           */
    PUNPCKHDQ  ( MM3, MM3 )                     /*    pa1    |    pa1    |    pa1    |    pa1    */

#if GMBT_ALPHA_PLUS_ONE
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */

    PSUBW      ( MM4, MM3 )                     /*   pa1 + 1 |   pa1 + 1 |   pa1 + 1 |   pa1 + 1 */
#endif

#if GMBT_SIGNED_ARITHMETIC
    PSUBW      ( MM1, MM2 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */

    PSLLW      ( CONST(8), MM1 )		/*                    q1 << 8                    */

#if GMBT_ROUNDOFF
    MOVQ       ( MM2, MM4 )
#endif

    PMULLW     ( MM3, MM2 )			/*              t1 = (q1 - p1)*pa1               */

#if GMBT_ROUNDOFF
    PSRLW      ( CONST(15), MM4 )		/*                 q1 > p1 ? 1 : 0               */

    PSLLW      ( CONST(8), MM4 )		/*             q1 > p1 ? 0x100 : 0               */

    PSUBW      ( MM4, MM2 )                     /*                  t1 -=? 0x100                 */
#endif

#else
    PCMPEQW    ( MM4, MM4 )			/*   0xffff  |   0xffff  |   0xffff  |   0xffff  */
    PUNPCKLBW  ( MM0, MM4 )			/*   0x00ff  |   0x00ff  |   0x00ff  |   0x00ff  */
    MOVQ       ( MM4, MM0 )
    
    PMULLW     ( MM3, MM2 )			/*                     p1*pa1                    */

    PSUBW      ( MM3, MM0 )			/* 255 - pa1 | 255 - pa1 | 255 - pa1 | 255 - pa1 */

    PMULLW     ( MM0, MM1 )			/*                  q1*(255 - pa1)               */

    PADDW      ( MM1, MM2 )			/*           t1 = p1*pa1 + q1*(255 - pa1)        */
#endif

#if GMBT_ROUNDOFF
    MOVQ       ( CONTENT(const_80), MM4 )

    PADDW      ( MM4, MM2 )                     /*                 t1 += 0x80                    */
#endif

#if GMBT_GEOMETRIC_SERIES
    MOVQ       ( MM2, MM3 )

    PSRLW      ( CONST(8), MM3 )		/*                    t1 >> 8                    */

    PADDW      ( MM3, MM2 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */
#endif

#if GMBT_SIGNED_ARITHMETIC
    PADDW      ( MM1, MM2 )			/*              (t1/255 + q1) << 8               */
#endif

    PSRLW      ( CONST(8), MM2 )		/*    sa1    |    sb1    |    sg1    |    sr1    */
    
    PACKUSWB   ( MM0, MM2 )			/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */
    MOVD       ( MM2, REGIND(EDI) )
a207 1
LLBL (GMBT_done):
d211 1
a211 1
LLBL (GMBT_return):
d213 139
a351 5
    POP_L      ( EBX )
    POP_L      ( EDI )
    POP_L      ( ESI )
    MOV_L      ( EBP, ESP )
    POP_L      ( EBP )
@


1.1.1.3
log
@That's what OpenBSD will, probably, ship as XF4 in 3.5
their last sync against XFree86 4.3-current has been
imported into our vendor branch, too
@
text
@a0 2
/* $XFree86: xc/extras/Mesa/src/X86/mmx_blend.S,v 1.7 2003/11/04 01:03:35 dawes Exp $ */

d7 2
a8 4

/* integer multiplication - alpha plus one
 *
 * makes the following approximation to the division (Sree)
d16 1
a16 3
 * note that MX1 is a register with 0xffffffffffffffff constant which can be easily obtained making
 *
 *   PCMPEQW    ( MX1, MX1 )
d18 1
a18 9
#define GMB_MULT_AP1( MP1, MA1, MP2, MA2, MX1 ) \
    PSUBW      ( MX1, MA1 )			/*   a1 + 1  |   a1 + 1  |   a1 + 1  |   a1 + 1  */	;\
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
													;\
TWO(PSUBW      ( MX1, MA2 ))			/*   a2 + 1  |   a2 + 1  |   a2 + 1  |   a2 + 1  */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*               t1 >> 8 ~= t1/255               */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*               t2 >> 8 ~= t2/255               */	
d20 2
a21 4

/* integer multiplication - geometric series
 *
 * takes the geometric series approximation to the division
d32 1
a32 15
#define GMB_MULT_GS( MP1, MA1, MP2, MA2 ) \
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
													;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */
d34 1
a34 3

/* integer multiplication - geometric series plus rounding
 *
a40 24
 *
 * note that M80 is register with the 0x0080008000800080 constant
 */
#define GMB_MULT_GSR( MP1, MA1, MP2, MA2, M80 ) \
    PMULLW     ( MP1, MA1 )			/*                  t1 = p1*a1                   */	;\
    PADDW      ( M80, MA1 )			/*                 t1 += 0x80                    */	;\
													;\
TWO(PMULLW     ( MP2, MA2 ))			/*                  t2 = p2*a2                   */	;\
TWO(PADDW      ( M80, MA2 ))			/*                 t2 += 0x80                    */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
													;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */


/* linear interpolation - geometric series 
d42 1
a42 23
#define GMB_LERP_GS( MP1, MQ1, MA1, MP2, MQ2, MA2) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */
d44 1
a44 2

/* linear interpolation - geometric series with roundoff
d46 1
a46 1
 * this is a generalization of Blinn's formula to signed arithmetic
d48 1
a48 1
 * note that M80 is a register with the 0x0080008000800080 constant
d50 1
a50 35
#define GMB_LERP_GSR( MP1, MQ1, MA1, MP2, MQ2, MA2, M80) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    PSRLW      ( CONST(15), MP1 )		/*                 q1 > p1 ? 1 : 0               */	;\
TWO(PSRLW      ( CONST(15), MP2 ))		/*                 q2 > q2 ? 1 : 0               */	;\
													;\
    PSLLW      ( CONST(8), MP1 )		/*             q1 > p1 ? 0x100 : 0               */	;\
TWO(PSLLW      ( CONST(8), MP2 ))		/*             q2 > q2 ? 0x100 : 0               */	;\
													;\
    PSUBW      ( MP1, MA1 )			/*                  t1 -=? 0x100                 */	;\
TWO(PSUBW      ( MP2, MA2 ))			/*                  t2 -=? 0x100                 */	;\
 													;\
    PADDW      ( M80, MA1 )			/*                 t1 += 0x80                    */	;\
TWO(PADDW      ( M80, MA2 ))			/*                 t2 += 0x80                    */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MP1, MA1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
TWO(PADDW      ( MP2, MA2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */
d52 4
a55 2

/* linear interpolation - geometric series with correction
d57 1
a57 1
 * instead of the roundoff this adds a small correction to satisfy the OpenGL criteria
d59 1
a59 1
 *   t/255 ~= (t + (t >> 8) + (t >> 15)) >> 8
d61 2
a62 1
 * note that although is faster than rounding off it doesn't give always the exact results
d64 58
a121 29
#define GMB_LERP_GSC( MP1, MQ1, MA1, MP2, MQ2, MA2) \
    PSUBW      ( MQ1, MP1 )                     /* pa1 - qa1 | pb1 - qb1 | pg1 - qg1 | pr1 - qr1 */	;\
    PSLLW      ( CONST(8), MQ1 )		/*                    q1 << 8                    */	;\
    PMULLW     ( MP1, MA1 )			/*              t1 = (q1 - p1)*pa1               */	;\
													;\
TWO(PSUBW      ( MQ2, MP2 ))                    /* pa2 - qa2 | pb2 - qb2 | pg2 - qg2 | pr2 - qr2 */	;\
TWO(PSLLW      ( CONST(8), MQ2 ))		/*                    q2 << 8                    */	;\
TWO(PMULLW     ( MP2, MA2 ))			/*              t2 = (q2 - p2)*pa2               */	;\
													;\
    MOVQ       ( MA1, MP1 )										;\
    PSRLW      ( CONST(8), MA1 )		/*                    t1 >> 8                    */	;\
													;\
TWO(MOVQ       ( MA2, MP2 ))										;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*                    t2 >> 8                    */	;\
													;\
    PADDW      ( MA1, MP1 )			/*        t1 + (t1 >> 8) ~= (t1/255) << 8        */	;\
    PSRLW      ( CONST(7), MA1 )		/*                    t1 >> 15                   */	;\
													;\
TWO(PADDW      ( MA2, MP2 ))			/*        t2 + (t2 >> 8) ~= (t2/255) << 8        */	;\
TWO(PSRLW      ( CONST(7), MA2 ))		/*                    t2 >> 15                   */	;\
													;\
    PADDW      ( MP1, MA1 )			/*  t1 + (t1 >> 8) + (t1 >>15) ~= (t1/255) << 8  */	;\
TWO(PADDW      ( MP2, MA2 ))			/*  t2 + (t2 >> 8) + (t2 >>15) ~= (t2/255) << 8  */	;\
													;\
    PADDW      ( MQ1, MA1 )			/*              (t1/255 + q1) << 8               */	;\
TWO(PADDW      ( MQ2, MA2 ))			/*              (t2/255 + q2) << 8               */	;\
													;\
    PSRLW      ( CONST(8), MA1 )		/*    sa1    |    sb1    |    sg1    |    sr1    */	;\
TWO(PSRLW      ( CONST(8), MA2 ))		/*    sa2    |    sb2    |    sg2    |    sr2    */
d123 2
d126 76
a201 37
/* common blending setup code
 *
 * note that M00 is a register with 0x0000000000000000 constant which can be easily obtained making
 *
 *   PXOR      ( M00, M00 )
 */
#define GMB_LOAD(rgba, dest, MPP, MQQ) \
ONE(MOVD       ( REGIND(rgba), MPP ))		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */	;\
ONE(MOVD       ( REGIND(dest), MQQ ))		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */	;\
													;\
TWO(MOVQ       ( REGIND(rgba), MPP ))		/* qa2 | qb2 | qg2 | qr2 | qa1 | qb1 | qg1 | qr1 */	;\
TWO(MOVQ       ( REGIND(dest), MQQ ))		/* pa2 | pb2 | pg2 | pr2 | pa1 | pb1 | pg1 | pr1 */

#define GMB_UNPACK(MP1, MQ1, MP2, MQ2, M00) \
TWO(MOVQ       ( MP1, MP2 ))										;\
TWO(MOVQ       ( MQ1, MQ2 ))										;\
													;\
    PUNPCKLBW  ( M00, MQ1 )			/*    qa1    |    qb1    |    qg1    |    qr1    */	;\
TWO(PUNPCKHBW  ( M00, MQ2 ))                    /*    qa2    |    qb2    |    qg2    |    qr2    */	;\
    PUNPCKLBW  ( M00, MP1 )			/*    pa1    |    pb1    |    pg1    |    pr1    */	;\
TWO(PUNPCKHBW  ( M00, MP2 ))                    /*    pa2    |    pb2    |    pg2    |    pr2    */

#define GMB_ALPHA(MP1, MA1, MP2, MA2) \
    MOVQ       ( MP1, MA1 )										;\
TWO(MOVQ       ( MP2, MA2 ))										;\
													;\
    PUNPCKHWD  ( MA1, MA1 )			/*    pa1    |    pa1    |           |           */	;\
TWO(PUNPCKHWD  ( MA2, MA2 ))			/*    pa2    |    pa2    |           |           */	;\
    PUNPCKHDQ  ( MA1, MA1 )                     /*    pa1    |    pa1    |    pa1    |    pa1    */	;\
TWO(PUNPCKHDQ  ( MA2, MA2 ))                    /*    pa2    |    pa2    |    pa2    |    pa2    */

#define GMB_PACK( MS1, MS2 ) \
    PACKUSWB   ( MS2, MS1 )			/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */	;\

#define GMB_STORE(rgba, MSS ) \
ONE(MOVD       ( MSS, REGIND(rgba) ))		/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */	;\
TWO(MOVQ       ( MSS, REGIND(rgba) ))		/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */
d203 1
d205 1
a205 1
    SEG_DATA
d207 2
a208 3
ALIGNDATA8
const_0080:
    D_LONG 0x00800080, 0x00800080
d210 2
a211 2
const_80:
    D_LONG 0x80808080, 0x80808080
d213 110
a322 1
    SEG_TEXT
d324 1
d326 2
a327 2
/* Blend transparency function
 */
d329 2
a330 2
#define TAG(x) CONCAT(x,_transparency)
#define LLTAG(x) LLBL2(x,_transparency)
a331 1
#define INIT \
d334 5
a338 7
#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    GMB_UNPACK( MM1, MM2, MM4, MM5, MM0 )								;\
    GMB_ALPHA( MM1, MM3, MM4, MM6 )									;\
    GMB_LERP_GSC( MM1, MM2, MM3, MM4, MM5, MM6 )							;\
    GMB_PACK( MM3, MM6 )										;\
    GMB_STORE( rgba, MM3 )
d340 1
a340 1
#include "mmx_blendtmp.h"
d342 2
d345 5
a349 4
/* Blend add function
 *
 * FIXME: Add some loop unrolling here...
 */
d351 2
a352 2
#define TAG(x) CONCAT(x,_add)
#define LLTAG(x) LLBL2(x,_add)
d354 1
a354 1
#define INIT
d356 3
a358 9
#define MAIN( rgba, dest ) \
ONE(MOVD       ( REGIND(rgba), MM1 ))		/*     |     |     |     | qa1 | qb1 | qg1 | qr1 */	;\
ONE(MOVD       ( REGIND(dest), MM2 ))		/*     |     |     |     | pa1 | pb1 | pg1 | pr1 */	;\
ONE(PADDUSB    ( MM2, MM1 ))										;\
ONE(MOVD       ( MM1, REGIND(rgba) ))		/*     |     |     |     | sa1 | sb1 | sg1 | sr1 */	;\
													;\
TWO(MOVQ       ( REGIND(rgba), MM1 ))		/* qa2 | qb2 | qg2 | qr2 | qa1 | qb1 | qg1 | qr1 */	;\
TWO(PADDUSB    ( REGIND(dest), MM1 ))		/* sa2 | sb2 | sg2 | sr2 | sa1 | sb1 | sg1 | sr1 */	;\
TWO(MOVQ       ( MM1, REGIND(rgba) ))
d360 1
a360 1
#include "mmx_blendtmp.h"
d362 2
d365 1
a365 2
/* Blend min function
 */
d367 2
a368 2
#define TAG(x) CONCAT(x,_min)
#define LLTAG(x) LLBL2(x,_min)
d370 6
a375 2
#define INIT \
    MOVQ       ( CONTENT(const_80), MM7 )	/* 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80*/
d377 1
a377 11
#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    MOVQ       ( MM1, MM3 )										;\
    MOVQ       ( MM2, MM4 )										;\
    PXOR       ( MM7, MM3 )			/*              unsigned -> signed               */	;\
    PXOR       ( MM7, MM4 )			/*              unsigned -> signed               */	;\
    PCMPGTB    ( MM3, MM4 )			/*                 q > p ? 0xff : 0x00           */	;\
    PAND       ( MM4, MM1 )			/*                 q > p ? p : 0                 */	;\
    PANDN      ( MM2, MM4 )			/*                 q > p ? 0 : q                 */	;\
    POR        ( MM1, MM4 )			/*                 q > p ? p : q                 */	;\
    GMB_STORE( rgba, MM4 )
d379 1
a379 1
#include "mmx_blendtmp.h"
d381 2
d384 2
a385 2
/* Blend max function
 */
d387 2
a388 2
#define TAG(x) CONCAT(x,_max)
#define LLTAG(x) LLBL2(x,_max)
d390 2
a391 2
#define INIT \
    MOVQ       ( CONTENT(const_80), MM7 )	/* 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80| 0x80*/
d393 1
a393 11
#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    MOVQ       ( MM1, MM3 )										;\
    MOVQ       ( MM2, MM4 )										;\
    PXOR       ( MM7, MM3 )			/*              unsigned -> signed               */	;\
    PXOR       ( MM7, MM4 )			/*              unsigned -> signed               */	;\
    PCMPGTB    ( MM3, MM4 )			/*                 q > p ? 0xff : 0x00           */	;\
    PAND       ( MM4, MM2 )			/*                 q > p ? q : 0                 */	;\
    PANDN      ( MM1, MM4 )			/*                 q > p ? 0 : p                 */	;\
    POR        ( MM2, MM4 )			/*                 q > p ? p : q                 */	;\
    GMB_STORE( rgba, MM4 )
d395 2
a396 1
#include "mmx_blendtmp.h"
d398 3
d402 4
a405 2
/* Blend modulate function
 */
d407 1
a407 2
#define TAG(x) CONCAT(x,_modulate)
#define LLTAG(x) LLBL2(x,_modulate)
d409 1
a409 10
#define INIT \
    PXOR       ( MM0, MM0 )			/*   0x0000  |   0x0000  |   0x0000  |   0x0000  */	;\
    MOVQ       ( CONTENT(const_0080), MM7 )	/*   0x0080  |   0x0080  |   0x0080  |   0x0080  */

#define MAIN( rgba, dest ) \
    GMB_LOAD( rgba, dest, MM1, MM2 )									;\
    GMB_UNPACK( MM1, MM2, MM4, MM5, MM0 )								;\
    GMB_MULT_GSR( MM1, MM2, MM4, MM5, MM7 )								;\
    GMB_PACK( MM2, MM5 )										;\
    GMB_STORE( rgba, MM2 )
d411 1
a411 1
#include "mmx_blendtmp.h"
d413 6
@


