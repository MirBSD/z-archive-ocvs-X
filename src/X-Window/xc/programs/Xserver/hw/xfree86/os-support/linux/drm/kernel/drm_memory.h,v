head	1.1;
branch	1.1.1;
access;
symbols
	tg-mergetmp-2:1.1.1.3
	cvs-200410241530:1.1.1.3
	cvs-200410012000:1.1.1.3
	cvs-200407221130:1.1.1.3
	cvs-200407141120:1.1.1.3
	cvs-200406231010:1.1.1.3
	MIRBSD_7quater:1.1.1.2
	cvs-200405271510:1.1.1.3
	XFree86_4_4_0:1.1.9.1
	cvs-200403021700:1.1.1.3
	XFREE86_20040213:1.1.9.1
	xc:1.1.9
	cvs-200401291925:1.1.1.2
	MIRBSD_7_ALPHA:1.1.1.2.0.4
	MIRBSD_7:1.1.1.2.0.2
	MIRBSD_7ter:1.1.1.2
	cvs-20011091815:1.1.1.2
	cvs-200309162130:1.1.1.2
	cvs-200308302005:1.1.1.2
	ctmx-0387:1.1.1.2
	ctmx-0384:1.1.1.2
	MIRBSD_5:1.1.1.2
	ctmx-0375:1.1.1.2
	ctmx-0373:1.1.1.2
	ctm-0371:1.1.1.2
	ctm-0370:1.1.1.2
	MIRBSD_4:1.1.1.2
	ctm-0363:1.1.1.2
	ctm-0359:1.1.1.2
	ctm-0349:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2003.03.22.20.08.44;	author tg;	state Exp;
branches
	1.1.1.1
	1.1.9.1;
next	;

1.1.1.1
date	2003.03.22.20.08.44;	author tg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2003.04.08.18.37.35;	author tg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2004.03.02.18.25.16;	author tg;	state Stab;
branches;
next	;

1.1.9.1
date	2004.02.14.19.25.14;	author tg;	state Exp;
branches;
next	;


desc
@@


1.1
log
@Initial revision
@
text
@/* drm_memory.h -- Memory management wrappers for DRM -*- linux-c -*-
 * Created: Thu Feb  4 14:00:34 1999 by faith@@valinux.com
 *
 * Copyright 1999 Precision Insight, Inc., Cedar Park, Texas.
 * Copyright 2000 VA Linux Systems, Inc., Sunnyvale, California.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Rickard E. (Rik) Faith <faith@@valinux.com>
 *    Gareth Hughes <gareth@@valinux.com>
 */

#define __NO_VERSION__
#include <linux/config.h>
#include "drmP.h"
#include <linux/wrapper.h>

typedef struct drm_mem_stats {
	const char	  *name;
	int		  succeed_count;
	int		  free_count;
	int		  fail_count;
	unsigned long	  bytes_allocated;
	unsigned long	  bytes_freed;
} drm_mem_stats_t;

static spinlock_t	  DRM(mem_lock)	     = SPIN_LOCK_UNLOCKED;
static unsigned long	  DRM(ram_available) = 0; /* In pages */
static unsigned long	  DRM(ram_used)      = 0;
static drm_mem_stats_t	  DRM(mem_stats)[]   = {
	[DRM_MEM_DMA]	    = { "dmabufs"  },
	[DRM_MEM_SAREA]	    = { "sareas"   },
	[DRM_MEM_DRIVER]    = { "driver"   },
	[DRM_MEM_MAGIC]	    = { "magic"	   },
	[DRM_MEM_IOCTLS]    = { "ioctltab" },
	[DRM_MEM_MAPS]	    = { "maplist"  },
	[DRM_MEM_VMAS]	    = { "vmalist"  },
	[DRM_MEM_BUFS]	    = { "buflist"  },
	[DRM_MEM_SEGS]	    = { "seglist"  },
	[DRM_MEM_PAGES]	    = { "pagelist" },
	[DRM_MEM_FILES]	    = { "files"	   },
	[DRM_MEM_QUEUES]    = { "queues"   },
	[DRM_MEM_CMDS]	    = { "commands" },
	[DRM_MEM_MAPPINGS]  = { "mappings" },
	[DRM_MEM_BUFLISTS]  = { "buflists" },
	[DRM_MEM_AGPLISTS]  = { "agplist"  },
	[DRM_MEM_SGLISTS]   = { "sglist"   },
	[DRM_MEM_TOTALAGP]  = { "totalagp" },
	[DRM_MEM_BOUNDAGP]  = { "boundagp" },
	[DRM_MEM_CTXBITMAP] = { "ctxbitmap"},
	[DRM_MEM_STUB]      = { "stub"     },
	{ NULL, 0, }		/* Last entry must be null */
};

void DRM(mem_init)(void)
{
	drm_mem_stats_t *mem;
	struct sysinfo	si;

	for (mem = DRM(mem_stats); mem->name; ++mem) {
		mem->succeed_count   = 0;
		mem->free_count	     = 0;
		mem->fail_count	     = 0;
		mem->bytes_allocated = 0;
		mem->bytes_freed     = 0;
	}

	si_meminfo(&si);
	DRM(ram_available) = si.totalram;
	DRM(ram_used)	   = 0;
}

/* drm_mem_info is called whenever a process reads /dev/drm/mem. */

static int DRM(_mem_info)(char *buf, char **start, off_t offset,
			  int request, int *eof, void *data)
{
	drm_mem_stats_t *pt;
	int             len = 0;

	if (offset > DRM_PROC_LIMIT) {
		*eof = 1;
		return 0;
	}

	*eof   = 0;
	*start = &buf[offset];

	DRM_PROC_PRINT("		  total counts			"
		       " |    outstanding  \n");
	DRM_PROC_PRINT("type	   alloc freed fail	bytes	   freed"
		       " | allocs      bytes\n\n");
	DRM_PROC_PRINT("%-9.9s %5d %5d %4d %10lu kB         |\n",
		       "system", 0, 0, 0,
		       DRM(ram_available) << (PAGE_SHIFT - 10));
	DRM_PROC_PRINT("%-9.9s %5d %5d %4d %10lu kB         |\n",
		       "locked", 0, 0, 0, DRM(ram_used) >> 10);
	DRM_PROC_PRINT("\n");
	for (pt = DRM(mem_stats); pt->name; pt++) {
		DRM_PROC_PRINT("%-9.9s %5d %5d %4d %10lu %10lu | %6d %10ld\n",
			       pt->name,
			       pt->succeed_count,
			       pt->free_count,
			       pt->fail_count,
			       pt->bytes_allocated,
			       pt->bytes_freed,
			       pt->succeed_count - pt->free_count,
			       (long)pt->bytes_allocated
			       - (long)pt->bytes_freed);
	}

	if (len > request + offset) return request;
	*eof = 1;
	return len - offset;
}

int DRM(mem_info)(char *buf, char **start, off_t offset,
		  int len, int *eof, void *data)
{
	int ret;

	spin_lock(&DRM(mem_lock));
	ret = DRM(_mem_info)(buf, start, offset, len, eof, data);
	spin_unlock(&DRM(mem_lock));
	return ret;
}

void *DRM(alloc)(size_t size, int area)
{
	void *pt;

	if (!size) {
		DRM_MEM_ERROR(area, "Allocating 0 bytes\n");
		return NULL;
	}

	if (!(pt = kmalloc(size, GFP_KERNEL))) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[area].fail_count;
		spin_unlock(&DRM(mem_lock));
		return NULL;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[area].succeed_count;
	DRM(mem_stats)[area].bytes_allocated += size;
	spin_unlock(&DRM(mem_lock));
	return pt;
}

void *DRM(realloc)(void *oldpt, size_t oldsize, size_t size, int area)
{
	void *pt;

	if (!(pt = DRM(alloc)(size, area))) return NULL;
	if (oldpt && oldsize) {
		memcpy(pt, oldpt, oldsize);
		DRM(free)(oldpt, oldsize, area);
	}
	return pt;
}

char *DRM(strdup)(const char *s, int area)
{
	char *pt;
	int	 length = s ? strlen(s) : 0;

	if (!(pt = DRM(alloc)(length+1, area))) return NULL;
	strcpy(pt, s);
	return pt;
}

void DRM(strfree)(const char *s, int area)
{
	unsigned int size;

	if (!s) return;

	size = 1 + (s ? strlen(s) : 0);
	DRM(free)((void *)s, size, area);
}

void DRM(free)(void *pt, size_t size, int area)
{
	int alloc_count;
	int free_count;

	if (!pt) DRM_MEM_ERROR(area, "Attempt to free NULL pointer\n");
	else	 kfree(pt);
	spin_lock(&DRM(mem_lock));
	DRM(mem_stats)[area].bytes_freed += size;
	free_count  = ++DRM(mem_stats)[area].free_count;
	alloc_count =	DRM(mem_stats)[area].succeed_count;
	spin_unlock(&DRM(mem_lock));
	if (free_count > alloc_count) {
		DRM_MEM_ERROR(area, "Excess frees: %d frees, %d allocs\n",
			      free_count, alloc_count);
	}
}

unsigned long DRM(alloc_pages)(int order, int area)
{
	unsigned long address;
	unsigned long bytes	  = PAGE_SIZE << order;
	unsigned long addr;
	unsigned int  sz;

	spin_lock(&DRM(mem_lock));
	if ((DRM(ram_used) >> PAGE_SHIFT)
	    > (DRM_RAM_PERCENT * DRM(ram_available)) / 100) {
		spin_unlock(&DRM(mem_lock));
		return 0;
	}
	spin_unlock(&DRM(mem_lock));

	address = __get_free_pages(GFP_KERNEL, order);
	if (!address) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[area].fail_count;
		spin_unlock(&DRM(mem_lock));
		return 0;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[area].succeed_count;
	DRM(mem_stats)[area].bytes_allocated += bytes;
	DRM(ram_used)		             += bytes;
	spin_unlock(&DRM(mem_lock));


				/* Zero outside the lock */
	memset((void *)address, 0, bytes);

				/* Reserve */
	for (addr = address, sz = bytes;
	     sz > 0;
	     addr += PAGE_SIZE, sz -= PAGE_SIZE) {
		mem_map_reserve(virt_to_page(addr));
	}

	return address;
}

void DRM(free_pages)(unsigned long address, int order, int area)
{
	unsigned long bytes = PAGE_SIZE << order;
	int		  alloc_count;
	int		  free_count;
	unsigned long addr;
	unsigned int  sz;

	if (!address) {
		DRM_MEM_ERROR(area, "Attempt to free address 0\n");
	} else {
				/* Unreserve */
		for (addr = address, sz = bytes;
		     sz > 0;
		     addr += PAGE_SIZE, sz -= PAGE_SIZE) {
			mem_map_unreserve(virt_to_page(addr));
		}
		free_pages(address, order);
	}

	spin_lock(&DRM(mem_lock));
	free_count  = ++DRM(mem_stats)[area].free_count;
	alloc_count =	DRM(mem_stats)[area].succeed_count;
	DRM(mem_stats)[area].bytes_freed += bytes;
	DRM(ram_used)			 -= bytes;
	spin_unlock(&DRM(mem_lock));
	if (free_count > alloc_count) {
		DRM_MEM_ERROR(area,
			      "Excess frees: %d frees, %d allocs\n",
			      free_count, alloc_count);
	}
}

void *DRM(ioremap)(unsigned long offset, unsigned long size)
{
	void *pt;

	if (!size) {
		DRM_MEM_ERROR(DRM_MEM_MAPPINGS,
			      "Mapping 0 bytes at 0x%08lx\n", offset);
		return NULL;
	}

	if (!(pt = ioremap(offset, size))) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[DRM_MEM_MAPPINGS].fail_count;
		spin_unlock(&DRM(mem_lock));
		return NULL;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[DRM_MEM_MAPPINGS].succeed_count;
	DRM(mem_stats)[DRM_MEM_MAPPINGS].bytes_allocated += size;
	spin_unlock(&DRM(mem_lock));
	return pt;
}

void DRM(ioremapfree)(void *pt, unsigned long size)
{
	int alloc_count;
	int free_count;

	if (!pt)
		DRM_MEM_ERROR(DRM_MEM_MAPPINGS,
			      "Attempt to free NULL pointer\n");
	else
		iounmap(pt);

	spin_lock(&DRM(mem_lock));
	DRM(mem_stats)[DRM_MEM_MAPPINGS].bytes_freed += size;
	free_count  = ++DRM(mem_stats)[DRM_MEM_MAPPINGS].free_count;
	alloc_count =	DRM(mem_stats)[DRM_MEM_MAPPINGS].succeed_count;
	spin_unlock(&DRM(mem_lock));
	if (free_count > alloc_count) {
		DRM_MEM_ERROR(DRM_MEM_MAPPINGS,
			      "Excess frees: %d frees, %d allocs\n",
			      free_count, alloc_count);
	}
}

#if __REALLY_HAVE_AGP

agp_memory *DRM(alloc_agp)(int pages, u32 type)
{
	agp_memory *handle;

	if (!pages) {
		DRM_MEM_ERROR(DRM_MEM_TOTALAGP, "Allocating 0 pages\n");
		return NULL;
	}

	if ((handle = DRM(agp_allocate_memory)(pages, type))) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[DRM_MEM_TOTALAGP].succeed_count;
		DRM(mem_stats)[DRM_MEM_TOTALAGP].bytes_allocated
			+= pages << PAGE_SHIFT;
		spin_unlock(&DRM(mem_lock));
		return handle;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[DRM_MEM_TOTALAGP].fail_count;
	spin_unlock(&DRM(mem_lock));
	return NULL;
}

int DRM(free_agp)(agp_memory *handle, int pages)
{
	int           alloc_count;
	int           free_count;
	int           retval = -EINVAL;

	if (!handle) {
		DRM_MEM_ERROR(DRM_MEM_TOTALAGP,
			      "Attempt to free NULL AGP handle\n");
		return retval;;
	}

	if (DRM(agp_free_memory)(handle)) {
		spin_lock(&DRM(mem_lock));
		free_count  = ++DRM(mem_stats)[DRM_MEM_TOTALAGP].free_count;
		alloc_count =   DRM(mem_stats)[DRM_MEM_TOTALAGP].succeed_count;
		DRM(mem_stats)[DRM_MEM_TOTALAGP].bytes_freed
			+= pages << PAGE_SHIFT;
		spin_unlock(&DRM(mem_lock));
		if (free_count > alloc_count) {
			DRM_MEM_ERROR(DRM_MEM_TOTALAGP,
				      "Excess frees: %d frees, %d allocs\n",
				      free_count, alloc_count);
		}
		return 0;
	}
	return retval;
}

int DRM(bind_agp)(agp_memory *handle, unsigned int start)
{
	int retcode = -EINVAL;

	if (!handle) {
		DRM_MEM_ERROR(DRM_MEM_BOUNDAGP,
			      "Attempt to bind NULL AGP handle\n");
		return retcode;
	}

	if (!(retcode = DRM(agp_bind_memory)(handle, start))) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[DRM_MEM_BOUNDAGP].succeed_count;
		DRM(mem_stats)[DRM_MEM_BOUNDAGP].bytes_allocated
			+= handle->page_count << PAGE_SHIFT;
		spin_unlock(&DRM(mem_lock));
		return retcode;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[DRM_MEM_BOUNDAGP].fail_count;
	spin_unlock(&DRM(mem_lock));
	return retcode;
}

int DRM(unbind_agp)(agp_memory *handle)
{
	int alloc_count;
	int free_count;
	int retcode = -EINVAL;

	if (!handle) {
		DRM_MEM_ERROR(DRM_MEM_BOUNDAGP,
			      "Attempt to unbind NULL AGP handle\n");
		return retcode;
	}

	if ((retcode = DRM(agp_unbind_memory)(handle))) return retcode;
	spin_lock(&DRM(mem_lock));
	free_count  = ++DRM(mem_stats)[DRM_MEM_BOUNDAGP].free_count;
	alloc_count = DRM(mem_stats)[DRM_MEM_BOUNDAGP].succeed_count;
	DRM(mem_stats)[DRM_MEM_BOUNDAGP].bytes_freed
		+= handle->page_count << PAGE_SHIFT;
	spin_unlock(&DRM(mem_lock));
	if (free_count > alloc_count) {
		DRM_MEM_ERROR(DRM_MEM_BOUNDAGP,
			      "Excess frees: %d frees, %d allocs\n",
			      free_count, alloc_count);
	}
	return retcode;
}
#endif
@


1.1.9.1
log
@OpenBSD just has imported exactly this tree into their vendor branch,
called the same tag, in XF4/xc
This is, apparently, the last XFree86 snapshot before the licence change
(ie, addition of the advertising clause)

Since the developers don't see any problems with that, and we would like
to integrate improvements done by the remaining one or two (or so) XFree86
developers (j/k), this prepares enabling us to update X-Window in the future.
@
text
@d1 1
a1 9
/** 
 * \file drm_memory.h 
 * Memory management wrappers for DRM
 *
 * \author Rickard E. (Rik) Faith <faith@@valinux.com>
 * \author Gareth Hughes <gareth@@valinux.com>
 */

/* 
d26 4
d35 1
d37 36
a72 6
/**
 * Cut down version of drm_memory_debug.h, which used to be called
 * drm_memory.h.  If you want the debug functionality, change 0 to 1
 * below.
 */
#define DEBUG_MEMORY 0
d74 4
a77 4
/* Need the 4-argument version of vmap().  */
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)

#include <linux/vmalloc.h>
d79 6
a84 33
#ifdef HAVE_PAGE_AGP
#include <asm/agp.h>
#else
# ifdef __powerpc__
#  define PAGE_AGP	__pgprot(_PAGE_KERNEL | _PAGE_NO_CACHE)
# else
#  define PAGE_AGP	PAGE_KERNEL
# endif
#endif

#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)
# define pte_offset_kernel(dir, address)	pte_offset(dir, address)
# define pte_pfn(pte)				(pte_page(pte) - mem_map)
# define pfn_to_page(pfn)			(mem_map + (pfn))
#endif

/*
 * Find the drm_map that covers the range [offset, offset+size).
 */
static inline drm_map_t *
drm_lookup_map (unsigned long offset, unsigned long size, drm_device_t *dev)
{
	struct list_head *list;
	drm_map_list_t *r_list;
	drm_map_t *map;

	list_for_each(list, &dev->maplist->head) {
		r_list = (drm_map_list_t *) list;
		map = r_list->map;
		if (!map)
			continue;
		if (map->offset <= offset && (offset + size) <= (map->offset + map->size))
			return map;
a85 23
	return NULL;
}

static inline void *
agp_remap (unsigned long offset, unsigned long size, drm_device_t *dev)
{
	unsigned long *phys_addr_map, i, num_pages = PAGE_ALIGN(size) / PAGE_SIZE;
	struct drm_agp_mem *agpmem;
	struct page **page_map;
	void *addr;

	size = PAGE_ALIGN(size);

#ifdef __alpha__
	offset -= dev->hose->mem_space->start;
#endif

	for (agpmem = dev->agp->memory; agpmem; agpmem = agpmem->next)
		if (agpmem->bound <= offset
		    && (agpmem->bound + (agpmem->pages << PAGE_SHIFT)) >= (offset + size))
			break;
	if (!agpmem)
		return NULL;
d87 3
a89 17
	/*
	 * OK, we're mapping AGP space on a chipset/platform on which memory accesses by
	 * the CPU do not get remapped by the GART.  We fix this by using the kernel's
	 * page-table instead (that's probably faster anyhow...).
	 */
	/* note: use vmalloc() because num_pages could be large... */
	page_map = vmalloc(num_pages * sizeof(struct page *));
	if (!page_map)
		return NULL;

	phys_addr_map = agpmem->memory->memory + (offset - agpmem->bound) / PAGE_SIZE;
	for (i = 0; i < num_pages; ++i)
		page_map[i] = pfn_to_page(phys_addr_map[i] >> PAGE_SHIFT);
	addr = vmap(page_map, num_pages, VM_IOREMAP, PAGE_AGP);
	vfree(page_map);

	return addr;
d92 1
a92 10
static inline unsigned long
drm_follow_page (void *vaddr)
{
	pgd_t *pgd = pgd_offset_k((unsigned long) vaddr);
	pmd_t *pmd = pmd_offset(pgd, (unsigned long) vaddr);
	pte_t *ptep = pte_offset_kernel(pmd, (unsigned long) vaddr);
	return pte_pfn(*ptep) << PAGE_SHIFT;
}

#endif /* __REALLY_HAVE_AGP && defined(VMAP_4_ARGS) */
d94 2
a95 1
static inline void *drm_ioremap(unsigned long offset, unsigned long size, drm_device_t *dev)
d97 2
a98 3
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	if (dev->agp && dev->agp->cant_use_aperture) {
		drm_map_t *map = drm_lookup_map(offset, size, dev);
d100 3
a102 2
		if (map && map->type == _DRM_AGP)
			return agp_remap(offset, size, dev);
a103 4
#endif

	return ioremap(offset, size);
}
d105 2
a106 6
static inline void *drm_ioremap_nocache(unsigned long offset, unsigned long size,
					drm_device_t *dev)
{
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	if (dev->agp && dev->agp->cant_use_aperture) {
		drm_map_t *map = drm_lookup_map(offset, size, dev);
d108 21
a128 2
		if (map && map->type == _DRM_AGP)
			return agp_remap(offset, size, dev);
a129 34
#endif

	return ioremap_nocache(offset, size);
}

static inline void drm_ioremapfree(void *pt, unsigned long size, drm_device_t *dev)
{
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	/*
	 * This is a bit ugly.  It would be much cleaner if the DRM API would use separate
	 * routines for handling mappings in the AGP space.  Hopefully this can be done in
	 * a future revision of the interface...
	 */
	if (dev->agp && dev->agp->cant_use_aperture
	    && ((unsigned long) pt >= VMALLOC_START && (unsigned long) pt < VMALLOC_END))
	{
		unsigned long offset;
		drm_map_t *map;

		offset = drm_follow_page(pt) | ((unsigned long) pt & ~PAGE_MASK);
		map = drm_lookup_map(offset, size, dev);
		if (map && map->type == _DRM_AGP) {
			vunmap(pt);
			return;
		}
	}
#endif

	iounmap(pt);
}

#if DEBUG_MEMORY
#include "drm_memory_debug.h"
#else
d131 3
a133 3
/** No-op. */
void DRM(mem_init)(void)
{
a135 13
/**
 * Called when "/proc/dri/%dev%/mem" is read.
 * 
 * \param buf output buffer.
 * \param start start of output data.
 * \param offset requested start offset.
 * \param len requested number of bytes.
 * \param eof whether there is no more data to return.
 * \param data private data.
 * \return number of written bytes.
 *
 * No-op. 
 */
d139 6
a144 1
	return 0;
a146 1
/** Wrapper around kmalloc() */
d149 1
a149 2
	return kmalloc(size, GFP_KERNEL);
}
d151 4
a154 4
/** Wrapper around kmalloc() */
void *DRM(calloc)(size_t size, size_t nmemb, int area)
{
	void *addr;
d156 11
a166 5
	addr = kmalloc(size * nmemb, GFP_KERNEL);
	if (addr != NULL)
		memset((void *)addr, 0, size * nmemb);

	return addr;
a168 1
/** Wrapper around kmalloc() and kfree() */
d173 1
a173 1
	if (!(pt = kmalloc(size, GFP_KERNEL))) return NULL;
d176 1
a176 1
		kfree(oldpt);
d181 20
a200 1
/** Wrapper around kfree() */
d203 14
a216 1
	kfree(pt);
a218 9
/**
 * Allocate pages.
 *
 * \param order size order.
 * \param area memory area. (Not used.)
 * \return page address on success, or zero on failure.
 *
 * Allocate and reserve free pages.
 */
d226 8
d235 4
a238 1
	if (!address) 
d240 7
d248 1
a248 1
				/* Zero */
d255 1
a255 1
		SetPageReserved(virt_to_page(addr));
a260 9
/**
 * Free pages.
 * 
 * \param address address of the pages to free.
 * \param order size order.
 * \param area memory area. (Not used.)
 *
 * Unreserve and free pages allocated by alloc_pages().
 */
d264 2
d269 11
a279 2
	if (!address) 
		return;
d281 10
a290 5
	/* Unreserve */
	for (addr = address, sz = bytes;
	     sz > 0;
	     addr += PAGE_SIZE, sz -= PAGE_SIZE) {
		ClearPageReserved(virt_to_page(addr));
a291 2

	free_pages(address, order);
d294 1
a294 2
/** Wrapper around drm_ioremap() */
void *DRM(ioremap)(unsigned long offset, unsigned long size, drm_device_t *dev)
d296 19
a314 1
	return drm_ioremap(offset, size, dev);
d317 1
a317 2
/** Wrapper around drm_ioremap_nocache() */
void *DRM(ioremap_nocache)(unsigned long offset, unsigned long size, drm_device_t *dev)
d319 2
a320 2
	return drm_ioremap_nocache(offset, size, dev);
}
d322 16
a337 4
/** Wrapper around drm_iounmap() */
void DRM(ioremapfree)(void *pt, unsigned long size, drm_device_t *dev)
{
	drm_ioremapfree(pt, size, dev);
d341 2
a342 2
/** Wrapper around agp_allocate_memory() */
DRM_AGP_MEM *DRM(alloc_agp)(int pages, u32 type)
d344 19
a362 1
	return DRM(agp_allocate_memory)(pages, type);
d365 1
a365 2
/** Wrapper around agp_free_memory() */
int DRM(free_agp)(DRM_AGP_MEM *handle, int pages)
d367 25
a391 1
	return DRM(agp_free_memory)(handle) ? 0 : -EINVAL;
d394 1
a394 2
/** Wrapper around agp_bind_memory() */
int DRM(bind_agp)(DRM_AGP_MEM *handle, unsigned int start)
d396 33
a428 2
	return DRM(agp_bind_memory)(handle, start);
}
d430 13
a442 4
/** Wrapper around agp_unbind_memory() */
int DRM(unbind_agp)(DRM_AGP_MEM *handle)
{
	return DRM(agp_unbind_memory)(handle);
d444 1
a444 2
#endif /* agp */
#endif /* debug_memory */
@


1.1.1.1
log
@Import OpenBSD 3.3 XF4 repository from CTM 3132 the first time
This finalizes starting an OpenBSD-mirabile (aka MirBSD) repository.

### MirBSD is:
# Copyright (c) 1982-2003 by Thorsten "mirabile" Glaser <x86@@ePost.de>
# Copyright © 1968-2003  The authors of And contributors to UNIX®, the
#       C Language, BSD/Berkeley Unix; 386BSD, NetBSD 1.1 and OpenBSD.
#
# Anyone who obtained a copy of this work is hereby permitted to freely use,
# distribute, modify, merge, sublicence, give away or sell it as long as the
# authors are given due credit and the following notice is retained:
#
# This work is provided "as is", with no explicit or implicit warranty what-
# soever. Use it only at your own risk. In no event may an author or contri-
# butor be held liable for any damage, directly or indirectly, that origina-
# ted through or is caused by creation or modification of this work.

MirBSD is my private tree. MirBSD does not differ very much from OpenBSD
and intentionally tracks OpenBSD. That's why it _is_ OpenBSD, just not the
official one. It's like with DarrenBSD.

At time of this writing, no advertising for MirBSD must be done,
because the advertising clause has not yet been sorted out.

http://templeofhate.com/tglaser/MirBSD/index.php
@
text
@@


1.1.1.2
log
@The X-Windowing System

Import XFree86 4.3 from OpenBSD by CTM, in the hope it's stable
@
text
@a316 23
void *DRM(ioremap_nocache)(unsigned long offset, unsigned long size)
{
	void *pt;

	if (!size) {
		DRM_MEM_ERROR(DRM_MEM_MAPPINGS,
			      "Mapping 0 bytes at 0x%08lx\n", offset);
		return NULL;
	}

	if (!(pt = ioremap_nocache(offset, size))) {
		spin_lock(&DRM(mem_lock));
		++DRM(mem_stats)[DRM_MEM_MAPPINGS].fail_count;
		spin_unlock(&DRM(mem_lock));
		return NULL;
	}
	spin_lock(&DRM(mem_lock));
	++DRM(mem_stats)[DRM_MEM_MAPPINGS].succeed_count;
	DRM(mem_stats)[DRM_MEM_MAPPINGS].bytes_allocated += size;
	spin_unlock(&DRM(mem_lock));
	return pt;
}

@


1.1.1.3
log
@That's what OpenBSD will, probably, ship as XF4 in 3.5
their last sync against XFree86 4.3-current has been
imported into our vendor branch, too
@
text
@d1 1
a1 9
/** 
 * \file drm_memory.h 
 * Memory management wrappers for DRM
 *
 * \author Rickard E. (Rik) Faith <faith@@valinux.com>
 * \author Gareth Hughes <gareth@@valinux.com>
 */

/* 
d26 4
d35 1
d37 36
a72 6
/**
 * Cut down version of drm_memory_debug.h, which used to be called
 * drm_memory.h.  If you want the debug functionality, change 0 to 1
 * below.
 */
#define DEBUG_MEMORY 0
d74 4
a77 4
/* Need the 4-argument version of vmap().  */
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)

#include <linux/vmalloc.h>
d79 6
a84 33
#ifdef HAVE_PAGE_AGP
#include <asm/agp.h>
#else
# ifdef __powerpc__
#  define PAGE_AGP	__pgprot(_PAGE_KERNEL | _PAGE_NO_CACHE)
# else
#  define PAGE_AGP	PAGE_KERNEL
# endif
#endif

#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)
# define pte_offset_kernel(dir, address)	pte_offset(dir, address)
# define pte_pfn(pte)				(pte_page(pte) - mem_map)
# define pfn_to_page(pfn)			(mem_map + (pfn))
#endif

/*
 * Find the drm_map that covers the range [offset, offset+size).
 */
static inline drm_map_t *
drm_lookup_map (unsigned long offset, unsigned long size, drm_device_t *dev)
{
	struct list_head *list;
	drm_map_list_t *r_list;
	drm_map_t *map;

	list_for_each(list, &dev->maplist->head) {
		r_list = (drm_map_list_t *) list;
		map = r_list->map;
		if (!map)
			continue;
		if (map->offset <= offset && (offset + size) <= (map->offset + map->size))
			return map;
a85 2
	return NULL;
}
d87 3
a89 47
static inline void *
agp_remap (unsigned long offset, unsigned long size, drm_device_t *dev)
{
	unsigned long *phys_addr_map, i, num_pages = PAGE_ALIGN(size) / PAGE_SIZE;
	struct drm_agp_mem *agpmem;
	struct page **page_map;
	void *addr;

	size = PAGE_ALIGN(size);

#ifdef __alpha__
	offset -= dev->hose->mem_space->start;
#endif

	for (agpmem = dev->agp->memory; agpmem; agpmem = agpmem->next)
		if (agpmem->bound <= offset
		    && (agpmem->bound + (agpmem->pages << PAGE_SHIFT)) >= (offset + size))
			break;
	if (!agpmem)
		return NULL;

	/*
	 * OK, we're mapping AGP space on a chipset/platform on which memory accesses by
	 * the CPU do not get remapped by the GART.  We fix this by using the kernel's
	 * page-table instead (that's probably faster anyhow...).
	 */
	/* note: use vmalloc() because num_pages could be large... */
	page_map = vmalloc(num_pages * sizeof(struct page *));
	if (!page_map)
		return NULL;

	phys_addr_map = agpmem->memory->memory + (offset - agpmem->bound) / PAGE_SIZE;
	for (i = 0; i < num_pages; ++i)
		page_map[i] = pfn_to_page(phys_addr_map[i] >> PAGE_SHIFT);
	addr = vmap(page_map, num_pages, VM_IOREMAP, PAGE_AGP);
	vfree(page_map);

	return addr;
}

static inline unsigned long
drm_follow_page (void *vaddr)
{
	pgd_t *pgd = pgd_offset_k((unsigned long) vaddr);
	pmd_t *pmd = pmd_offset(pgd, (unsigned long) vaddr);
	pte_t *ptep = pte_offset_kernel(pmd, (unsigned long) vaddr);
	return pte_pfn(*ptep) << PAGE_SHIFT;
d92 1
a92 1
#endif /* __REALLY_HAVE_AGP && defined(VMAP_4_ARGS) */
d94 2
a95 1
static inline void *drm_ioremap(unsigned long offset, unsigned long size, drm_device_t *dev)
d97 2
a98 3
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	if (dev->agp && dev->agp->cant_use_aperture) {
		drm_map_t *map = drm_lookup_map(offset, size, dev);
d100 3
a102 2
		if (map && map->type == _DRM_AGP)
			return agp_remap(offset, size, dev);
a103 1
#endif
d105 2
a106 2
	return ioremap(offset, size);
}
d108 21
a128 35
static inline void *drm_ioremap_nocache(unsigned long offset, unsigned long size,
					drm_device_t *dev)
{
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	if (dev->agp && dev->agp->cant_use_aperture) {
		drm_map_t *map = drm_lookup_map(offset, size, dev);

		if (map && map->type == _DRM_AGP)
			return agp_remap(offset, size, dev);
	}
#endif

	return ioremap_nocache(offset, size);
}

static inline void drm_ioremapfree(void *pt, unsigned long size, drm_device_t *dev)
{
#if __REALLY_HAVE_AGP && defined(VMAP_4_ARGS)
	/*
	 * This is a bit ugly.  It would be much cleaner if the DRM API would use separate
	 * routines for handling mappings in the AGP space.  Hopefully this can be done in
	 * a future revision of the interface...
	 */
	if (dev->agp && dev->agp->cant_use_aperture
	    && ((unsigned long) pt >= VMALLOC_START && (unsigned long) pt < VMALLOC_END))
	{
		unsigned long offset;
		drm_map_t *map;

		offset = drm_follow_page(pt) | ((unsigned long) pt & ~PAGE_MASK);
		map = drm_lookup_map(offset, size, dev);
		if (map && map->type == _DRM_AGP) {
			vunmap(pt);
			return;
		}
a129 4
#endif

	iounmap(pt);
}
d131 3
a133 7
#if DEBUG_MEMORY
#include "drm_memory_debug.h"
#else

/** No-op. */
void DRM(mem_init)(void)
{
a135 13
/**
 * Called when "/proc/dri/%dev%/mem" is read.
 * 
 * \param buf output buffer.
 * \param start start of output data.
 * \param offset requested start offset.
 * \param len requested number of bytes.
 * \param eof whether there is no more data to return.
 * \param data private data.
 * \return number of written bytes.
 *
 * No-op. 
 */
d139 6
a144 1
	return 0;
a146 1
/** Wrapper around kmalloc() */
d149 1
a149 2
	return kmalloc(size, GFP_KERNEL);
}
d151 4
a154 4
/** Wrapper around kmalloc() */
void *DRM(calloc)(size_t size, size_t nmemb, int area)
{
	void *addr;
d156 11
a166 5
	addr = kmalloc(size * nmemb, GFP_KERNEL);
	if (addr != NULL)
		memset((void *)addr, 0, size * nmemb);

	return addr;
a168 1
/** Wrapper around kmalloc() and kfree() */
d173 1
a173 1
	if (!(pt = kmalloc(size, GFP_KERNEL))) return NULL;
d176 1
a176 1
		kfree(oldpt);
d181 20
a200 1
/** Wrapper around kfree() */
d203 14
a216 1
	kfree(pt);
a218 9
/**
 * Allocate pages.
 *
 * \param order size order.
 * \param area memory area. (Not used.)
 * \return page address on success, or zero on failure.
 *
 * Allocate and reserve free pages.
 */
d226 8
d235 4
a238 1
	if (!address) 
d240 7
d248 1
a248 1
				/* Zero */
d255 1
a255 1
		SetPageReserved(virt_to_page(addr));
a260 9
/**
 * Free pages.
 * 
 * \param address address of the pages to free.
 * \param order size order.
 * \param area memory area. (Not used.)
 *
 * Unreserve and free pages allocated by alloc_pages().
 */
d264 2
d269 11
a279 2
	if (!address) 
		return;
d281 10
a290 5
	/* Unreserve */
	for (addr = address, sz = bytes;
	     sz > 0;
	     addr += PAGE_SIZE, sz -= PAGE_SIZE) {
		ClearPageReserved(virt_to_page(addr));
a291 2

	free_pages(address, order);
d294 1
a294 2
/** Wrapper around drm_ioremap() */
void *DRM(ioremap)(unsigned long offset, unsigned long size, drm_device_t *dev)
d296 19
a314 1
	return drm_ioremap(offset, size, dev);
d317 1
a317 2
/** Wrapper around drm_ioremap_nocache() */
void *DRM(ioremap_nocache)(unsigned long offset, unsigned long size, drm_device_t *dev)
d319 19
a337 1
	return drm_ioremap_nocache(offset, size, dev);
d340 1
a340 2
/** Wrapper around drm_iounmap() */
void DRM(ioremapfree)(void *pt, unsigned long size, drm_device_t *dev)
d342 19
a360 1
	drm_ioremapfree(pt, size, dev);
d364 2
a365 2
/** Wrapper around agp_allocate_memory() */
DRM_AGP_MEM *DRM(alloc_agp)(int pages, u32 type)
d367 19
a385 1
	return DRM(agp_allocate_memory)(pages, type);
d388 1
a388 2
/** Wrapper around agp_free_memory() */
int DRM(free_agp)(DRM_AGP_MEM *handle, int pages)
d390 25
a414 1
	return DRM(agp_free_memory)(handle) ? 0 : -EINVAL;
d417 1
a417 2
/** Wrapper around agp_bind_memory() */
int DRM(bind_agp)(DRM_AGP_MEM *handle, unsigned int start)
d419 33
a451 2
	return DRM(agp_bind_memory)(handle, start);
}
d453 13
a465 4
/** Wrapper around agp_unbind_memory() */
int DRM(unbind_agp)(DRM_AGP_MEM *handle)
{
	return DRM(agp_unbind_memory)(handle);
d467 1
a467 2
#endif /* agp */
#endif /* debug_memory */
@


