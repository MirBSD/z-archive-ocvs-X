head	1.1;
branch	1.1.1;
access;
symbols
	tg-mergetmp-2:1.1.1.3
	cvs-200410241530:1.1.1.3
	cvs-200410012000:1.1.1.3
	cvs-200407221130:1.1.1.3
	cvs-200407141120:1.1.1.3
	cvs-200406231010:1.1.1.3
	cvs-200406052200:1.1.1.3
	MIRBSD_7quater:1.1.1.2
	cvs-200405271510:1.1.1.3
	XFree86_4_4_0:1.1.9.1
	cvs-200403021700:1.1.1.3
	XFREE86_20040213:1.1.9.1
	xc:1.1.9
	cvs-200401291925:1.1.1.2
	MIRBSD_7_ALPHA:1.1.1.2.0.4
	MIRBSD_7:1.1.1.2.0.2
	MIRBSD_7ter:1.1.1.2
	cvs-20011091815:1.1.1.2
	cvs-200309162130:1.1.1.2
	cvs-200308302005:1.1.1.2
	ctmx-0387:1.1.1.2
	ctmx-0384:1.1.1.2
	MIRBSD_5:1.1.1.2
	ctmx-0375:1.1.1.2
	ctmx-0373:1.1.1.2
	ctm-0371:1.1.1.2
	ctm-0370:1.1.1.2
	MIRBSD_4:1.1.1.2
	ctm-0363:1.1.1.2
	ctm-0359:1.1.1.2
	ctm-0349:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2003.03.22.20.08.32;	author tg;	state Exp;
branches
	1.1.1.1
	1.1.9.1;
next	;

1.1.1.1
date	2003.03.22.20.08.32;	author tg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2003.04.08.18.37.29;	author tg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2004.03.02.18.24.35;	author tg;	state Stab;
branches;
next	;

1.1.9.1
date	2004.02.14.19.25.05;	author tg;	state Exp;
branches;
next	;


desc
@@


1.1
log
@Initial revision
@
text
@/* drm_dma.c -- DMA IOCTL and function support -*- linux-c -*-
 * Created: Fri Mar 19 14:30:16 1999 by faith@@valinux.com
 *
 * Copyright 1999, 2000 Precision Insight, Inc., Cedar Park, Texas.
 * Copyright 2000 VA Linux Systems, Inc., Sunnyvale, California.
 * All Rights Reserved.
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice (including the next
 * paragraph) shall be included in all copies or substantial portions of the
 * Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
 * VA LINUX SYSTEMS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM, DAMAGES OR
 * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
 * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
 * OTHER DEALINGS IN THE SOFTWARE.
 *
 * Authors:
 *    Rickard E. (Rik) Faith <faith@@valinux.com>
 *    Gareth Hughes <gareth@@valinux.com>
 */

#include <machine/bus.h>
#include <machine/resource.h>
#include <sys/rman.h>

#include "drmP.h"

#ifndef __HAVE_DMA_WAITQUEUE
#define __HAVE_DMA_WAITQUEUE	0
#endif
#ifndef __HAVE_DMA_RECLAIM
#define __HAVE_DMA_RECLAIM	0
#endif
#ifndef __HAVE_SHARED_IRQ
#define __HAVE_SHARED_IRQ	0
#endif

#if __HAVE_SHARED_IRQ
#define DRM_IRQ_TYPE		SA_SHIRQ
#else
#define DRM_IRQ_TYPE		0
#endif

#if __HAVE_DMA

int DRM(dma_setup)( drm_device_t *dev )
{
	int i;

	dev->dma = DRM(alloc)( sizeof(*dev->dma), DRM_MEM_DRIVER );
	if ( !dev->dma )
		DRM_OS_RETURN(ENOMEM);

	memset( dev->dma, 0, sizeof(*dev->dma) );

	for ( i = 0 ; i <= DRM_MAX_ORDER ; i++ )
		memset(&dev->dma->bufs[i], 0, sizeof(dev->dma->bufs[0]));

	return 0;
}

void DRM(dma_takedown)(drm_device_t *dev)
{
	drm_device_dma_t  *dma = dev->dma;
	int		  i, j;

	if (!dma) return;

				/* Clear dma buffers */
	for (i = 0; i <= DRM_MAX_ORDER; i++) {
		if (dma->bufs[i].seg_count) {
			DRM_DEBUG("order %d: buf_count = %d,"
				  " seg_count = %d\n",
				  i,
				  dma->bufs[i].buf_count,
				  dma->bufs[i].seg_count);
			for (j = 0; j < dma->bufs[i].seg_count; j++) {
				DRM(free_pages)(dma->bufs[i].seglist[j],
						dma->bufs[i].page_order,
						DRM_MEM_DMA);
			}
			DRM(free)(dma->bufs[i].seglist,
				  dma->bufs[i].seg_count
				  * sizeof(*dma->bufs[0].seglist),
				  DRM_MEM_SEGS);
		}
	   	if(dma->bufs[i].buf_count) {
		   	for(j = 0; j < dma->bufs[i].buf_count; j++) {
			   if(dma->bufs[i].buflist[j].dev_private) {
			      DRM(free)(dma->bufs[i].buflist[j].dev_private,
					dma->bufs[i].buflist[j].dev_priv_size,
					DRM_MEM_BUFS);
			   }
			}
		   	DRM(free)(dma->bufs[i].buflist,
				  dma->bufs[i].buf_count *
				  sizeof(*dma->bufs[0].buflist),
				  DRM_MEM_BUFS);
#if __HAVE_DMA_FREELIST
		   	DRM(freelist_destroy)(&dma->bufs[i].freelist);
#endif
		}
	}

	if (dma->buflist) {
		DRM(free)(dma->buflist,
			  dma->buf_count * sizeof(*dma->buflist),
			  DRM_MEM_BUFS);
	}

	if (dma->pagelist) {
		DRM(free)(dma->pagelist,
			  dma->page_count * sizeof(*dma->pagelist),
			  DRM_MEM_PAGES);
	}
	DRM(free)(dev->dma, sizeof(*dev->dma), DRM_MEM_DRIVER);
	dev->dma = NULL;
}


#if __HAVE_DMA_HISTOGRAM
/* This is slow, but is useful for debugging. */
int DRM(histogram_slot)(unsigned long count)
{
	int value = DRM_DMA_HISTOGRAM_INITIAL;
	int slot;

	for (slot = 0;
	     slot < DRM_DMA_HISTOGRAM_SLOTS;
	     ++slot, value = DRM_DMA_HISTOGRAM_NEXT(value)) {
		if (count < value) return slot;
	}
	return DRM_DMA_HISTOGRAM_SLOTS - 1;
}

void DRM(histogram_compute)(drm_device_t *dev, drm_buf_t *buf)
{
	cycles_t queued_to_dispatched;
	cycles_t dispatched_to_completed;
	cycles_t completed_to_freed;
	int	 q2d, d2c, c2f, q2c, q2f;

	if (buf->time_queued) {
		queued_to_dispatched	= (buf->time_dispatched
					   - buf->time_queued);
		dispatched_to_completed = (buf->time_completed
					   - buf->time_dispatched);
		completed_to_freed	= (buf->time_freed
					   - buf->time_completed);

		q2d = DRM(histogram_slot)(queued_to_dispatched);
		d2c = DRM(histogram_slot)(dispatched_to_completed);
		c2f = DRM(histogram_slot)(completed_to_freed);

		q2c = DRM(histogram_slot)(queued_to_dispatched
					  + dispatched_to_completed);
		q2f = DRM(histogram_slot)(queued_to_dispatched
					  + dispatched_to_completed
					  + completed_to_freed);

		atomic_inc(&dev->histo.total);
		atomic_inc(&dev->histo.queued_to_dispatched[q2d]);
		atomic_inc(&dev->histo.dispatched_to_completed[d2c]);
		atomic_inc(&dev->histo.completed_to_freed[c2f]);

		atomic_inc(&dev->histo.queued_to_completed[q2c]);
		atomic_inc(&dev->histo.queued_to_freed[q2f]);

	}
	buf->time_queued     = 0;
	buf->time_dispatched = 0;
	buf->time_completed  = 0;
	buf->time_freed	     = 0;
}
#endif

void DRM(free_buffer)(drm_device_t *dev, drm_buf_t *buf)
{
	if (!buf) return;

	buf->waiting  = 0;
	buf->pending  = 0;
	buf->pid      = 0;
	buf->used     = 0;
#if __HAVE_DMA_HISTOGRAM
	buf->time_completed = get_cycles();
#endif

	if ( buf->dma_wait ) {
		wakeup( &buf->dma_wait );
		buf->dma_wait = 0;
	}
#if __HAVE_DMA_FREELIST
	else {
		drm_device_dma_t *dma = dev->dma;
				/* If processes are waiting, the last one
				   to wake will put the buffer on the free
				   list.  If no processes are waiting, we
				   put the buffer on the freelist here. */
		DRM(freelist_put)(dev, &dma->bufs[buf->order].freelist, buf);
	}
#endif
}

#if !__HAVE_DMA_RECLAIM
void DRM(reclaim_buffers)(drm_device_t *dev, pid_t pid)
{
	drm_device_dma_t *dma = dev->dma;
	int		 i;

	if (!dma) return;
	for (i = 0; i < dma->buf_count; i++) {
		if (dma->buflist[i]->pid == pid) {
			switch (dma->buflist[i]->list) {
			case DRM_LIST_NONE:
				DRM(free_buffer)(dev, dma->buflist[i]);
				break;
			case DRM_LIST_WAIT:
				dma->buflist[i]->list = DRM_LIST_RECLAIM;
				break;
			default:
				/* Buffer already on hardware. */
				break;
			}
		}
	}
}
#endif


/* GH: This is a big hack for now...
 */
#if __HAVE_OLD_DMA

void DRM(clear_next_buffer)(drm_device_t *dev)
{
	drm_device_dma_t *dma = dev->dma;

	dma->next_buffer = NULL;
	if (dma->next_queue && !DRM_BUFCOUNT(&dma->next_queue->waitlist)) {
		DRM_OS_WAKEUP_INT(&dma->next_queue->flush_queue);
	}
	dma->next_queue	 = NULL;
}

int DRM(select_queue)(drm_device_t *dev, void (*wrapper)(unsigned long))
{
	int	   i;
	int	   candidate = -1;
	int	   j	     = jiffies;

	if (!dev) {
		DRM_ERROR("No device\n");
		return -1;
	}
	if (!dev->queuelist || !dev->queuelist[DRM_KERNEL_CONTEXT]) {
				/* This only happens between the time the
				   interrupt is initialized and the time
				   the queues are initialized. */
		return -1;
	}

				/* Doing "while locked" DMA? */
	if (DRM_WAITCOUNT(dev, DRM_KERNEL_CONTEXT)) {
		return DRM_KERNEL_CONTEXT;
	}

				/* If there are buffers on the last_context
				   queue, and we have not been executing
				   this context very long, continue to
				   execute this context. */
	if (dev->last_switch <= j
	    && dev->last_switch + DRM_TIME_SLICE > j
	    && DRM_WAITCOUNT(dev, dev->last_context)) {
		return dev->last_context;
	}

				/* Otherwise, find a candidate */
	for (i = dev->last_checked + 1; i < dev->queue_count; i++) {
		if (DRM_WAITCOUNT(dev, i)) {
			candidate = dev->last_checked = i;
			break;
		}
	}

	if (candidate < 0) {
		for (i = 0; i < dev->queue_count; i++) {
			if (DRM_WAITCOUNT(dev, i)) {
				candidate = dev->last_checked = i;
				break;
			}
		}
	}

	if (wrapper
	    && candidate >= 0
	    && candidate != dev->last_context
	    && dev->last_switch <= j
	    && dev->last_switch + DRM_TIME_SLICE > j) {
		int s = splclock();
		if (dev->timer.c_time != dev->last_switch + DRM_TIME_SLICE) {
			callout_reset(&dev->timer,
				      dev->last_switch + DRM_TIME_SLICE - j,
				      (void (*)(void *))wrapper,
				      dev);
		}
		splx(s);
		return -1;
	}

	return candidate;
}


int DRM(dma_enqueue)(drm_device_t *dev, drm_dma_t *d)
{
	int		  i;
	drm_queue_t	  *q;
	drm_buf_t	  *buf;
	int		  idx;
	int		  while_locked = 0;
	drm_device_dma_t  *dma = dev->dma;
	int		  error;

	DRM_DEBUG("%d\n", d->send_count);

	if (d->flags & _DRM_DMA_WHILE_LOCKED) {
		int context = dev->lock.hw_lock->lock;

		if (!_DRM_LOCK_IS_HELD(context)) {
			DRM_ERROR("No lock held during \"while locked\""
				  " request\n");
			DRM_OS_RETURN(EINVAL);
		}
		if (d->context != _DRM_LOCKING_CONTEXT(context)
		    && _DRM_LOCKING_CONTEXT(context) != DRM_KERNEL_CONTEXT) {
			DRM_ERROR("Lock held by %d while %d makes"
				  " \"while locked\" request\n",
				  _DRM_LOCKING_CONTEXT(context),
				  d->context);
			DRM_OS_RETURN(EINVAL);
		}
		q = dev->queuelist[DRM_KERNEL_CONTEXT];
		while_locked = 1;
	} else {
		q = dev->queuelist[d->context];
	}


	atomic_inc(&q->use_count);
	if (atomic_read(&q->block_write)) {
		atomic_inc(&q->block_count);
		for (;;) {
			if (!atomic_read(&q->block_write)) break;
			error = tsleep(&q->block_write, PZERO|PCATCH,
				       "dmawr", 0);
			if (error) {
				atomic_dec(&q->use_count);
				return error;
			}
		}
		atomic_dec(&q->block_count);
	}

	for (i = 0; i < d->send_count; i++) {
		idx = d->send_indices[i];
		if (idx < 0 || idx >= dma->buf_count) {
			atomic_dec(&q->use_count);
			DRM_ERROR("Index %d (of %d max)\n",
				  d->send_indices[i], dma->buf_count - 1);
			DRM_OS_RETURN(EINVAL);
		}
		buf = dma->buflist[ idx ];
		if (buf->pid != DRM_OS_CURRENTPID) {
			atomic_dec(&q->use_count);
			DRM_ERROR("Process %d using buffer owned by %d\n",
				  DRM_OS_CURRENTPID, buf->pid);
			DRM_OS_RETURN(EINVAL);
		}
		if (buf->list != DRM_LIST_NONE) {
			atomic_dec(&q->use_count);
			DRM_ERROR("Process %d using buffer %d on list %d\n",
				  DRM_OS_CURRENTPID, buf->idx, buf->list);
		}
		buf->used	  = d->send_sizes[i];
		buf->while_locked = while_locked;
		buf->context	  = d->context;
		if (!buf->used) {
			DRM_ERROR("Queueing 0 length buffer\n");
		}
		if (buf->pending) {
			atomic_dec(&q->use_count);
			DRM_ERROR("Queueing pending buffer:"
				  " buffer %d, offset %d\n",
				  d->send_indices[i], i);
			DRM_OS_RETURN(EINVAL);
		}
		if (buf->waiting) {
			atomic_dec(&q->use_count);
			DRM_ERROR("Queueing waiting buffer:"
				  " buffer %d, offset %d\n",
				  d->send_indices[i], i);
			DRM_OS_RETURN(EINVAL);
		}
		buf->waiting = 1;
		if (atomic_read(&q->use_count) == 1
		    || atomic_read(&q->finalization)) {
			DRM(free_buffer)(dev, buf);
		} else {
			DRM(waitlist_put)(&q->waitlist, buf);
			atomic_inc(&q->total_queued);
		}
	}
	atomic_dec(&q->use_count);

	return 0;
}

static int DRM(dma_get_buffers_of_order)(drm_device_t *dev, drm_dma_t *d,
					 int order)
{
	int		  i;
	drm_buf_t	  *buf;
	drm_device_dma_t  *dma = dev->dma;

	for (i = d->granted_count; i < d->request_count; i++) {
		buf = DRM(freelist_get)(&dma->bufs[order].freelist,
					d->flags & _DRM_DMA_WAIT);
		if (!buf) break;
		if (buf->pending || buf->waiting) {
			DRM_ERROR("Free buffer %d in use by %d (w%d, p%d)\n",
				  buf->idx,
				  buf->pid,
				  buf->waiting,
				  buf->pending);
		}
		buf->pid     = DRM_OS_CURRENTPID;
		if (DRM_OS_COPYTOUSR(&d->request_indices[i],
				 &buf->idx,
				 sizeof(buf->idx)))
			DRM_OS_RETURN(EFAULT);

		if (DRM_OS_COPYTOUSR(&d->request_sizes[i],
				 &buf->total,
				 sizeof(buf->total)))
			DRM_OS_RETURN(EFAULT);

		++d->granted_count;
	}
	return 0;
}


int DRM(dma_get_buffers)(drm_device_t *dev, drm_dma_t *dma)
{
	int		  order;
	int		  retcode = 0;
	int		  tmp_order;

	order = DRM(order)(dma->request_size);

	dma->granted_count = 0;
	retcode		   = DRM(dma_get_buffers_of_order)(dev, dma, order);

	if (dma->granted_count < dma->request_count
	    && (dma->flags & _DRM_DMA_SMALLER_OK)) {
		for (tmp_order = order - 1;
		     !retcode
			     && dma->granted_count < dma->request_count
			     && tmp_order >= DRM_MIN_ORDER;
		     --tmp_order) {

			retcode = DRM(dma_get_buffers_of_order)(dev, dma,
								tmp_order);
		}
	}

	if (dma->granted_count < dma->request_count
	    && (dma->flags & _DRM_DMA_LARGER_OK)) {
		for (tmp_order = order + 1;
		     !retcode
			     && dma->granted_count < dma->request_count
			     && tmp_order <= DRM_MAX_ORDER;
		     ++tmp_order) {

			retcode = DRM(dma_get_buffers_of_order)(dev, dma,
								tmp_order);
		}
	}
	return 0;
}

#endif /* __HAVE_OLD_DMA */


#if __HAVE_DMA_IRQ

int DRM(irq_install)( drm_device_t *dev, int irq )
{
	int rid;
	int retcode;

	if ( !irq )
		DRM_OS_RETURN(EINVAL);

	DRM_OS_LOCK;
	if ( dev->irq ) {
		DRM_OS_UNLOCK;
		DRM_OS_RETURN(EBUSY);
	}
	dev->irq = irq;
	DRM_OS_UNLOCK;

	DRM_DEBUG( "%s: irq=%d\n", __FUNCTION__, irq );

	dev->context_flag = 0;
	dev->interrupt_flag = 0;
	dev->dma_flag = 0;

	dev->dma->next_buffer = NULL;
	dev->dma->next_queue = NULL;
	dev->dma->this_buffer = NULL;

#if __HAVE_DMA_IRQ_BH
	TASK_INIT(&dev->task, 0, DRM(dma_immediate_bh), dev);
#endif

				/* Before installing handler */
	DRIVER_PREINSTALL();

				/* Install handler */
	rid = 0;
	dev->irqr = bus_alloc_resource(dev->device, SYS_RES_IRQ, &rid,
				      0, ~0, 1, RF_SHAREABLE);
	if (!dev->irqr)
		return ENOENT;
	
	retcode = bus_setup_intr(dev->device, dev->irqr, INTR_TYPE_TTY,
				 DRM(dma_service), dev, &dev->irqh);
	if ( retcode ) {
		DRM_OS_LOCK;
		bus_release_resource(dev->device, SYS_RES_IRQ, 0, dev->irqr);
		dev->irq = 0;
		DRM_OS_UNLOCK;
		return retcode;
	}

				/* After installing handler */
	DRIVER_POSTINSTALL();

	return 0;
}

int DRM(irq_uninstall)( drm_device_t *dev )
{
	int irq;

	DRM_OS_LOCK;
	irq = dev->irq;
	dev->irq = 0;
	DRM_OS_UNLOCK;

	if ( !irq )
		DRM_OS_RETURN(EINVAL);

	DRM_DEBUG( "%s: irq=%d\n", __FUNCTION__, irq );

	DRIVER_UNINSTALL();

	bus_teardown_intr(dev->device, dev->irqr, dev->irqh);
	bus_release_resource(dev->device, SYS_RES_IRQ, 0, dev->irqr);
	
	return 0;
}

int DRM(control)( DRM_OS_IOCTL )
{
	DRM_OS_DEVICE;
	drm_control_t ctl;

	DRM_OS_KRNFROMUSR( ctl, (drm_control_t *) data, sizeof(ctl) );

	switch ( ctl.func ) {
	case DRM_INST_HANDLER:
		return DRM(irq_install)( dev, ctl.irq );
	case DRM_UNINST_HANDLER:
		return DRM(irq_uninstall)( dev );
	default:
		DRM_OS_RETURN(EINVAL);
	}
}

#endif /* __HAVE_DMA_IRQ */

#endif /* __HAVE_DMA */
@


1.1.9.1
log
@OpenBSD just has imported exactly this tree into their vendor branch,
called the same tag, in XF4/xc
This is, apparently, the last XFree86 snapshot before the licence change
(ie, addition of the advertising clause)

Since the developers don't see any problems with that, and we would like
to integrate improvements done by the remaining one or two (or so) XFree86
developers (j/k), this prepares enabling us to update X-Window in the future.
@
text
@a29 1
 *
d32 4
d48 6
d58 1
d60 3
a62 3
	dev->dma = DRM(calloc)(1, sizeof(*dev->dma), DRM_MEM_DRIVER);
	if (dev->dma == NULL)
		return DRM_ERR(ENOMEM);
d64 4
a67 1
	DRM_SPININIT(dev->dma_lock, "drmdma");
d77 1
a77 2
	if (dma == NULL)
		return;
a80 1
#if __HAVE_PCI_DMA
d88 3
a90 4
				if (dma->bufs[i].seglist[j] != NULL)
					DRM(pci_free)(dev, dma->bufs[i].buf_size,
					    (void *)dma->bufs[i].seglist[j],
					    dma->bufs[i].seglist_bus[j]);
a95 4
			DRM(free)(dma->bufs[i].seglist_bus,
				  dma->bufs[i].seg_count
				  * sizeof(*dma->bufs[0].seglist_bus),
				  DRM_MEM_SEGS);
d97 4
a100 5
#endif /* __HAVE_PCI_DMA */

	   	if (dma->bufs[i].buf_count) {
		   	for (j = 0; j < dma->bufs[i].buf_count; j++) {
				DRM(free)(dma->bufs[i].buflist[j].dev_private,
d103 1
d109 3
d115 11
a125 4
	DRM(free)(dma->buflist, dma->buf_count * sizeof(*dma->buflist),
	    DRM_MEM_BUFS);
	DRM(free)(dma->pagelist, dma->page_count * sizeof(*dma->pagelist),
	    DRM_MEM_PAGES);
a127 1
	DRM_SPINUNINIT(dev->dma_lock);
d131 56
d191 1
d193 1
a193 1
	buf->filp     = NULL;
d195 18
d216 1
a216 1
void DRM(reclaim_buffers)(drm_device_t *dev, DRMFILE filp)
d223 1
a223 1
		if (dma->buflist[i]->filp == filp) {
d240 2
a241 4
#if !__HAVE_IRQ
/* This stub DRM_IOCTL_CONTROL handler is for the drivers that used to require
 * IRQs for DMA but no longer do.  It maintains compatibility with the X Servers
 * that try to use the control ioctl by simply returning success.
d243 3
a245 1
int DRM(control)( DRM_IOCTL_ARGS )
d247 342
d591 1
a591 1
	DRM_COPY_FROM_USER_IOCTL( ctl, (drm_control_t *) data, sizeof(ctl) );
d595 1
d597 1
a597 1
		return 0;
d599 1
a599 1
		return DRM_ERR(EINVAL);
d602 2
a603 1
#endif
@


1.1.1.1
log
@Import OpenBSD 3.3 XF4 repository from CTM 3132 the first time
This finalizes starting an OpenBSD-mirabile (aka MirBSD) repository.

### MirBSD is:
# Copyright (c) 1982-2003 by Thorsten "mirabile" Glaser <x86@@ePost.de>
# Copyright © 1968-2003  The authors of And contributors to UNIX®, the
#       C Language, BSD/Berkeley Unix; 386BSD, NetBSD 1.1 and OpenBSD.
#
# Anyone who obtained a copy of this work is hereby permitted to freely use,
# distribute, modify, merge, sublicence, give away or sell it as long as the
# authors are given due credit and the following notice is retained:
#
# This work is provided "as is", with no explicit or implicit warranty what-
# soever. Use it only at your own risk. In no event may an author or contri-
# butor be held liable for any damage, directly or indirectly, that origina-
# ted through or is caused by creation or modification of this work.

MirBSD is my private tree. MirBSD does not differ very much from OpenBSD
and intentionally tracks OpenBSD. That's why it _is_ OpenBSD, just not the
official one. It's like with DarrenBSD.

At time of this writing, no advertising for MirBSD must be done,
because the advertising clause has not yet been sorted out.

http://templeofhate.com/tglaser/MirBSD/index.php
@
text
@@


1.1.1.2
log
@The X-Windowing System

Import XFree86 4.3 from OpenBSD by CTM, in the hope it's stable
@
text
@d32 4
d48 6
d62 1
a62 1
		return DRM_ERR(ENOMEM);
d88 2
a89 2
				DRM(free)((void *)dma->bufs[i].seglist[j],
						dma->bufs[i].buf_size,
d200 1
a200 1
		wakeup( (void *)&buf->dma_wait );
d251 1
a251 1
		DRM_WAKEUP_INT(&dma->next_queue->flush_queue);
d343 1
a343 1
			return DRM_ERR(EINVAL);
d351 1
a351 1
			return DRM_ERR(EINVAL);
d381 1
a381 1
			return DRM_ERR(EINVAL);
d384 1
a384 1
		if (buf->pid != DRM_CURRENTPID) {
d387 2
a388 2
				  DRM_CURRENTPID, buf->pid);
			return DRM_ERR(EINVAL);
d393 1
a393 1
				  DRM_CURRENTPID, buf->idx, buf->list);
d406 1
a406 1
			return DRM_ERR(EINVAL);
d413 1
a413 1
			return DRM_ERR(EINVAL);
d447 2
a448 2
		buf->pid     = DRM_CURRENTPID;
		if (DRM_COPY_TO_USER(&d->request_indices[i],
d451 1
a451 1
			return DRM_ERR(EFAULT);
d453 1
a453 1
		if (DRM_COPY_TO_USER(&d->request_sizes[i],
d456 1
a456 1
			return DRM_ERR(EFAULT);
d510 1
d514 1
a514 1
		return DRM_ERR(EINVAL);
d516 1
a516 1
	DRM_LOCK;
d518 2
a519 2
		DRM_UNLOCK;
		return DRM_ERR(EBUSY);
d522 1
a522 1
	DRM_UNLOCK;
d539 1
a539 1
	DRM(driver_irq_preinstall)( dev );
d542 2
a543 2
	dev->irqrid = 0;
	dev->irqr = bus_alloc_resource(dev->device, SYS_RES_IRQ, &dev->irqrid,
d545 1
a545 5
	if (!dev->irqr) {
		DRM_LOCK;
		dev->irq = 0;
		dev->irqrid = 0;
		DRM_UNLOCK;
a546 1
	}
d551 2
a552 2
		DRM_LOCK;
		bus_release_resource(dev->device, SYS_RES_IRQ, dev->irqrid, dev->irqr);
d554 1
a554 2
		dev->irqrid = 0;
		DRM_UNLOCK;
d559 1
a559 1
	DRM(driver_irq_postinstall)( dev );
d567 2
a568 3
	int irqrid;
	
	DRM_LOCK;
a569 1
	irqrid = dev->irqrid;
d571 1
a571 2
	dev->irqrid = 0;
	DRM_UNLOCK;
d574 1
a574 1
		return DRM_ERR(EINVAL);
d578 1
a578 1
	DRM(driver_irq_uninstall)( dev );
d581 1
a581 1
	bus_release_resource(dev->device, SYS_RES_IRQ, irqrid, dev->irqr);
d586 1
a586 1
int DRM(control)( DRM_IOCTL_ARGS )
d588 1
a588 1
	DRM_DEVICE;
d591 1
a591 1
	DRM_COPY_FROM_USER_IOCTL( ctl, (drm_control_t *) data, sizeof(ctl) );
d599 1
a599 66
		return DRM_ERR(EINVAL);
	}
}

#if __HAVE_VBL_IRQ
int DRM(wait_vblank)( DRM_IOCTL_ARGS )
{
	DRM_DEVICE;
	drm_wait_vblank_t vblwait;
	struct timeval now;
	int ret;

	if (!dev->irq)
		return DRM_ERR(EINVAL);

	DRM_COPY_FROM_USER_IOCTL( vblwait, (drm_wait_vblank_t *)data,
				  sizeof(vblwait) );

	switch ( vblwait.request.type & ~_DRM_VBLANK_FLAGS_MASK ) {
	case _DRM_VBLANK_RELATIVE:
		vblwait.request.sequence += atomic_read( &dev->vbl_received );
	case _DRM_VBLANK_ABSOLUTE:
		break;
	default:
		return EINVAL;
	}

	if ( flags & _DRM_VBLANK_SIGNAL ) {
		/* Signals from vblank not supported on BSD yet */
		return EINVAL;
	}

	flags = vblwait.request.type & _DRM_VBLANK_FLAGS_MASK;
	
	ret = DRM(vblank_wait)(dev, &vblwait.request.sequence);
	
	microtime(&now);
	vblwait.reply.tval_sec = now.tv_sec;
	vblwait.reply.tval_usec = now.tv_usec;

	DRM_COPY_TO_USER_IOCTL( (drm_wait_vblank_t *)data, vblwait,
				sizeof(vblwait) );

	return ret;
}

void DRM(vbl_send_signals)( drm_device_t *dev ) {
	/* Signals from vblank not supported on BSD yet */
}

#endif /*  __HAVE_VBL_IRQ */

#else

int DRM(control)( DRM_IOCTL_ARGS )
{
	drm_control_t ctl;

	DRM_COPY_FROM_USER_IOCTL( ctl, (drm_control_t *) data, sizeof(ctl) );

	switch ( ctl.func ) {
	case DRM_INST_HANDLER:
	case DRM_UNINST_HANDLER:
		return 0;
	default:
		return DRM_ERR(EINVAL);
a605 1

@


1.1.1.3
log
@That's what OpenBSD will, probably, ship as XF4 in 3.5
their last sync against XFree86 4.3-current has been
imported into our vendor branch, too
@
text
@a29 1
 *
d48 1
d50 2
a51 2
	dev->dma = DRM(calloc)(1, sizeof(*dev->dma), DRM_MEM_DRIVER);
	if (dev->dma == NULL)
d54 4
a57 1
	DRM_SPININIT(dev->dma_lock, "drmdma");
d67 1
a67 2
	if (dma == NULL)
		return;
a70 1
#if __HAVE_PCI_DMA
d78 3
a80 4
				if (dma->bufs[i].seglist[j] != NULL)
					DRM(pci_free)(dev, dma->bufs[i].buf_size,
					    (void *)dma->bufs[i].seglist[j],
					    dma->bufs[i].seglist_bus[j]);
a85 4
			DRM(free)(dma->bufs[i].seglist_bus,
				  dma->bufs[i].seg_count
				  * sizeof(*dma->bufs[0].seglist_bus),
				  DRM_MEM_SEGS);
d87 4
a90 5
#endif /* __HAVE_PCI_DMA */

	   	if (dma->bufs[i].buf_count) {
		   	for (j = 0; j < dma->bufs[i].buf_count; j++) {
				DRM(free)(dma->bufs[i].buflist[j].dev_private,
d93 1
d99 3
d105 11
a115 4
	DRM(free)(dma->buflist, dma->buf_count * sizeof(*dma->buflist),
	    DRM_MEM_BUFS);
	DRM(free)(dma->pagelist, dma->page_count * sizeof(*dma->pagelist),
	    DRM_MEM_PAGES);
a117 1
	DRM_SPINUNINIT(dev->dma_lock);
d121 56
d181 1
d183 1
a183 1
	buf->filp     = NULL;
d185 18
d206 1
a206 1
void DRM(reclaim_buffers)(drm_device_t *dev, DRMFILE filp)
d213 1
a213 1
		if (dma->buflist[i]->filp == filp) {
d230 2
a231 4
#if !__HAVE_IRQ
/* This stub DRM_IOCTL_CONTROL handler is for the drivers that used to require
 * IRQs for DMA but no longer do.  It maintains compatibility with the X Servers
 * that try to use the control ioctl by simply returning success.
d233 418
d665 2
a666 1
#endif
d669 1
@


